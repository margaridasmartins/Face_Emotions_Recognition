{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Intensive Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions\n",
    "1. Define the global variables;\n",
    "2. Run the second snippet. It builds the network and saves the output to a folder displayed on the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST VARIABLES\n",
    "labelsGroup = [\n",
    "    [\"happy\", \"sad\"],\n",
    "]\n",
    "iterationsGroup = [100]\n",
    "hiddenLayersGroup = [\n",
    "    [144],\n",
    "]\n",
    "batchSize = 128\n",
    "hyperParametersGroup = [0, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "labelsGroup = [\n",
    "    [\"happy\", \"sad\"],\n",
    "    [\"fear\", \"angry\"],\n",
    "    [\"fear\", \"angry\", \"surprise\"],\n",
    "    [\"fear\", \"sad\", \"happy\"],\n",
    "    [\"happy\", \"angry\", \"neutral\"],\n",
    "    [\"fear\", \"angry\", \"surprise\", \"neutral\"],\n",
    "    [\"angry\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]\n",
    "]\n",
    "iterationsGroup = [1500]\n",
    "hiddenLayersGroup = [\n",
    "    [20],\n",
    "    [144],\n",
    "    [144, 144],\n",
    "    [300,200,100,50],\n",
    "    [300,100,100,100],\n",
    "]\n",
    "batchSize = 128\n",
    "hyperParametersGroup = [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(labels, pred, y):\n",
    "    \n",
    "    confusionTFPN = {}\n",
    "    confusionLabels = {}\n",
    "    \n",
    "    # Foreach emotion\n",
    "    for ie in range(len(labels)):\n",
    "        # TRUE AND FALSE POSITIVES AND NEGATIVES (TFPN)\n",
    "        \n",
    "        # Get indexes where emotion was predicted\n",
    "        ieIndexesPred = [i for i in range(pred.size) if pred[i]==ie]\n",
    "        ieIndexesNotPred = [i for i in range(pred.size) if pred[i]!=ie]\n",
    "\n",
    "        # Predicted, and Actual\n",
    "        TP = sum(pred[:,np.newaxis][ieIndexesPred]==y[ieIndexesPred])\n",
    "        # Predicted, but not actual\n",
    "        FP = sum(pred[:,np.newaxis][ieIndexesPred]!=y[ieIndexesPred])\n",
    "        # Not predicted, but actual\n",
    "        FN = sum(y[ieIndexesNotPred]==ie)\n",
    "        # Not predicted and not actual\n",
    "        TN = sum(y[ieIndexesNotPred]!=ie)\n",
    "\n",
    "        TP = TP[0] if TP else 0\n",
    "        FP = FP[0] if FP else 0\n",
    "        FN = FN[0] if FN else 0\n",
    "        TN = TN[0] if TN else 0\n",
    "        \n",
    "        confusionTFPN[labels[ie]] = {\n",
    "            'TP': TP,\n",
    "            'FP': FP,\n",
    "            'FN': FN,\n",
    "            'TN': TN\n",
    "        }\n",
    "        \n",
    "        # CONFUSION WITH OTHER labels (Confusion)\n",
    "        # For emotion e\n",
    "        # Count the number of predictions made for all classes\n",
    "        # Foreach emotion, check how many times it has been predicted \n",
    "        \n",
    "        # Get indexes where emotion is real\n",
    "        ieIndexesY = [i for i in range(y.size) if y[i]==ie]\n",
    "        \n",
    "        # Foreach matching prediction, check what emotion was predicted\n",
    "        confusionLabels[labels[ie]] = {\n",
    "            e: sum(pred[:,np.newaxis][ieIndexesY]==labels.index(e))[0] for e in labels\n",
    "        }\n",
    "        \n",
    "    return confusionTFPN, confusionLabels\n",
    "\n",
    "def outputConfusionTables(labels, testExamplesNumber, confusionTFPN, confusionLabels, axs, axsLine, axsTitle):\n",
    "     # TABLES\n",
    "    rows = tuple(labels)\n",
    "    \n",
    "    # TABLES / TFPN\n",
    "    # Output confusion matrix as plot table\n",
    "    data = [\n",
    "        [\n",
    "            f\"{vals['TP']} ({vals['TP']/testExamplesNumber*100:.2f}%)\",\n",
    "            f\"{vals['TN']} ({vals['TN']/testExamplesNumber*100:.2f}%)\",\n",
    "            f\"{vals['TP']+vals['TN']} ({(vals['TP']+vals['TN'])/testExamplesNumber*100:.2f}%)\",\n",
    "            f\"{vals['FP']} ({vals['FP']/testExamplesNumber*100:.2f}%)\",\n",
    "            f\"{vals['FN']} ({vals['FN']/testExamplesNumber*100:.2f}%)\",\n",
    "            f\"{vals['FP']+vals['FN']} ({(vals['FP']+vals['FN'])/testExamplesNumber*100:.2f}%)\",\n",
    "            vals['FP']+vals['FN']+vals['TP']+vals['TN']\n",
    "        ]\n",
    "        for _, vals in confusionTFPN.items()\n",
    "    ]\n",
    "    columns = ['TP (%)', 'TN (%)', 'T (%)', 'FP (%)', 'FN (%)', 'F (%)', f\"Total\"]\n",
    "    \n",
    "    # Colorize cells depending on value\n",
    "    cellColoursTF=plt.cm.Blues([\n",
    "        [ (vals['TP']+vals['TN'])/testExamplesNumber, (vals['FP']+vals['FN'])/testExamplesNumber ] for _, vals in confusionTFPN.items()\n",
    "    ])\n",
    "    cellColourPos=plt.cm.Greens([\n",
    "        [ vals['TP']/(vals['TP']+vals['FP']), vals['FP']/(vals['TP']+vals['FP']) ] for _, vals in confusionTFPN.items()\n",
    "    ])\n",
    "    cellColourNeg=plt.cm.Reds([\n",
    "        [ vals['TN']/(vals['TN']+vals['FN']), vals['FN']/(vals['TN']+vals['FN']) ] for _, vals in confusionTFPN.items()\n",
    "    ])\n",
    "    \n",
    "    cellColours = [\n",
    "        [\n",
    "            cellColourPos[i][0],\n",
    "            cellColourNeg[i][0],\n",
    "            cellColoursTF[i][0],\n",
    "            cellColourPos[i][1],\n",
    "            cellColourNeg[i][1],\n",
    "            cellColoursTF[i][1],\n",
    "            [0, 0, 0, 0]\n",
    "        ]\n",
    "        for i in range(len(rows))\n",
    "    ]\n",
    "        \n",
    "    the_table = axs[axsLine].table(\n",
    "      cellText=data,\n",
    "      rowLabels=rows,\n",
    "      colLabels=columns,\n",
    "      loc='center',\n",
    "      cellColours=cellColours\n",
    "    )\n",
    "    # the_table.scale(1.2, 1)\n",
    "    the_table.auto_set_font_size(False)\n",
    "    the_table.set_fontsize(20)\n",
    "    axs[axsLine].axis('off')\n",
    "    axs[axsLine].axis('tight')\n",
    "    axs[axsLine].set_title(f\"Confusion matrix {axsTitle}\", fontsize=20, pad=0)    \n",
    "    \n",
    "    # TABLES / Confusion    \n",
    "    # Output confusion matrix as plot table\n",
    "    data = [[o for _,o in others.items()] for _,others in confusionLabels.items()]\n",
    "    columns = rows\n",
    "    \n",
    "    # Colorize cells depending on value\n",
    "    vals = [o for _,others in confusionLabels.items() for _,o in others.items()]\n",
    "    normal = plt.Normalize(min(vals)-1, max(vals)+1)\n",
    "    cellColours=plt.cm.Blues(normal(data))\n",
    "        \n",
    "    the_table = axs[axsLine+1].table(\n",
    "      cellText=data,\n",
    "      rowLabels=rows,\n",
    "      colLabels=columns,\n",
    "      loc='center',\n",
    "      cellColours=cellColours\n",
    "    )\n",
    "    \n",
    "    the_table.set_fontsize(20)\n",
    "    # the_table.scale(1, 4)\n",
    "    axs[axsLine+1].axis('off')\n",
    "    axs[axsLine+1].axis('tight')\n",
    "    axs[axsLine+1].set_title(f\"True/Predicted {axsTitle}\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORT LIBRARIES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#to load matlab mat files\n",
    "from scipy.io import loadmat\n",
    "# for saving metrics\n",
    "import os \n",
    "import json\n",
    "# for neural network\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "if not os.path.exists('./metrics'):\n",
    "    os.makedirs('./metrics')\n",
    "\n",
    "# FOR EACH LABEL GROUP\n",
    "for labelNames in labelsGroup:\n",
    "    # LOAD FILES\n",
    "    print(\"\\n\\nLABELS\", ', '.join(labelNames))\n",
    "\n",
    "    # Load Training/Dev/Test data\n",
    "    mat=loadmat(f\"../datasets/train/{'_'.join(labelNames)}.mat\")\n",
    "    X, y = mat[\"X\"], mat[\"y\"]\n",
    "    matDev=loadmat(f\"../datasets/dev/{'_'.join(labelNames)}.mat\")\n",
    "    X_valid, y_valid = matDev[\"X\"], matDev[\"y\"]\n",
    "    matTest=loadmat(f\"../datasets/test/{'_'.join(labelNames)}.mat\")\n",
    "    X_test, y_test = matTest[\"X\"], matTest[\"y\"]\n",
    "    \n",
    "    # NUMBERS\n",
    "    m = X.shape[0] # number of training examples\n",
    "    labels = np.max(y)+1 # number of labels\n",
    "    features = X.shape[1] # number of features per example\n",
    "\n",
    "    # Output user feedback\n",
    "    print(f\"Loaded {m} traing examples with {labels} labels, each with {features} features (pixels).\")\n",
    "    print(f\"Loaded {X_valid.shape[0]} dev examples.\")\n",
    "    print(f\"Loaded {X_test.shape[0]} test examples.\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Create folder for metrics\n",
    "    labelFolder = f\"./metrics/{'_'.join(labelNames)}\"\n",
    "    if not os.path.exists(labelFolder):\n",
    "        os.makedirs(labelFolder)\n",
    "    if not os.path.exists(f\"{labelFolder}/history\"):\n",
    "        os.makedirs(f\"{labelFolder}/history\")\n",
    "    if not os.path.exists(f\"{labelFolder}/predict\"):\n",
    "        os.makedirs(f\"{labelFolder}/predict\")\n",
    "    if not os.path.exists(f\"{labelFolder}/archive\"):\n",
    "        os.makedirs(f\"{labelFolder}/archive\")\n",
    "    \n",
    "    # FOREACH HIDDEN LAYER\n",
    "    for hiddenLayers in hiddenLayersGroup:\n",
    "        # FOR EACH HYPER PARAMETER\n",
    "        for hyperParameter in hyperParametersGroup:\n",
    "            # FOR EACH ITERATION NUMBER\n",
    "            for iterations in iterationsGroup:\n",
    "                \n",
    "                hiddenLayersText = '_'.join(map(str, hiddenLayers)) if len(hiddenLayers)>1 else hiddenLayers[0]\n",
    "                print(hiddenLayersText)\n",
    "                combinationName = f\"{iterations}iter_{batchSize}batchS_{hyperParameter}hyper_{len(hiddenLayers)}hlayers__{hiddenLayersText}\"\n",
    "                folder = f\"{labelFolder}/archive/{combinationName}/\"\n",
    "                if not os.path.exists(folder):\n",
    "                    os.makedirs(folder)\n",
    "\n",
    "                print(f\"\\nBuilding network for {iterations} iterations and batch size of {batchSize} and {len(hiddenLayers)} hidden layers: {hiddenLayersText}...\")\n",
    "                print(\"With regularization!\" if hyperParameter else \"Without regularization!\")\n",
    "                print()\n",
    "\n",
    "                # BUILD NETWORK\n",
    "                # Create model\n",
    "                modelSeq = []\n",
    "                # Flattens each image (48x48) to 1x2304\n",
    "                modelSeq.append(keras.layers.Flatten(input_shape = [48, 48]))\n",
    "                # Hidden layers with relu activation function\n",
    "                for h in hiddenLayers:                        \n",
    "                    modelSeq.append(keras.layers.Dense(\n",
    "                        h, \n",
    "                        activation = \"relu\", \n",
    "                        bias_regularizer= keras.regularizers.l2(hyperParameter) if hyperParameter else None\n",
    "                    ))\n",
    "                # Output layer with softmax activation function\n",
    "                modelSeq.append(keras.layers.Dense(\n",
    "                    labels, \n",
    "                    activation = \"softmax\",\n",
    "                    bias_regularizer= keras.regularizers.l2(hyperParameter) if hyperParameter else None\n",
    "                ))\n",
    "\n",
    "                model = keras.models.Sequential(modelSeq)\n",
    "\n",
    "                # Compile model\n",
    "                model.compile(\n",
    "                    # Using sparse categorical crossentropy loss function\n",
    "                    loss = \"sparse_categorical_crossentropy\",\n",
    "                    # Using stochastic gradient descent as gradient descent\n",
    "                    optimizer = \"sgd\",\n",
    "                    # In addition to cost, we want accuracy to help understanding how the model is working \n",
    "                    metrics = [\"accuracy\"]\n",
    "                )\n",
    "\n",
    "                # Train the network\n",
    "                history = model.fit(\n",
    "                    X,\n",
    "                    y,\n",
    "                    epochs = iterations,\n",
    "                    batch_size = batchSize,\n",
    "                    validation_data = (X_valid, y_valid)\n",
    "                )\n",
    "\n",
    "                # METRICS (SAVE TO FILE)\n",
    "\n",
    "                # Model training history\n",
    "                with open(f\"{folder}/history.json\", \"w\") as f:\n",
    "                    json.dump(history.history, f)\n",
    "\n",
    "                # Test model evaluation\n",
    "                with open(f\"{folder}/evaluation.json\", \"w\") as f:\n",
    "                    json.dump(model.evaluate(X_test, y_test, return_dict=True), f)\n",
    "\n",
    "                # Prediction for test data\n",
    "                with open(f\"{folder}/predict.json\", \"w\") as f:\n",
    "                    json.dump(model.predict(X_test).tolist(), f)\n",
    "\n",
    "                print(f\"\\nModel trained and metrics saved to {folder}!\")\n",
    "\n",
    "                # GENERATE GRAPHS AND SAVE TO FILE\n",
    "\n",
    "                # Model training history\n",
    "                pd.DataFrame(history.history).plot(figsize = (16, 10))\n",
    "                plt.grid(True)\n",
    "                plt.gca().set_ylim(0, 1)\n",
    "                plt.title(\"Neural network training metrics\")\n",
    "                plt.savefig(f\"{labelFolder}/history/{combinationName}.png\")\n",
    "\n",
    "                # Prediction for test data\n",
    "                predict = model.predict(X_test)\n",
    "                y_pred = np.array([np.argmax(p) for p in predict])\n",
    "                confusionTFPN, confusionLabels = confusionMatrix(labelNames, y_pred, y_test)\n",
    "                fig, axs = plt.subplots(2,1)\n",
    "                outputConfusionTables(labelNames, y_test.size, confusionTFPN, confusionLabels, axs, 0, \"WITHOUT regularization\")\n",
    "                fig.set_size_inches(18,6*len(labelNames))\n",
    "                fig.subplots_adjust(left=0.2, top=20)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f\"{labelFolder}/predict/{combinationName}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
