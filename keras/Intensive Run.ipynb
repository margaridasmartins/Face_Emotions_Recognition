{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Intensive Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions\n",
    "1. Define the global variables;\n",
    "2. Run the second snippet. It builds the network and saves the output to a folder displayed on the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST VARIABLES\n",
    "labelsGroup = [\n",
    "    [\"happy\", \"sad\"],\n",
    "]\n",
    "iterationsGroup = [100]\n",
    "hiddenLayersGroup = [\n",
    "    [144],\n",
    "]\n",
    "batchSize = 128\n",
    "hyperParametersGroup = [0, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "labelsGroup = [\n",
    "    # Gon√ßalo\n",
    "    [\"happy\", \"neutral\"],\n",
    "    [\"angry\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"],\n",
    "    [\"fear\", \"angry\"],\n",
    "    [\"happy\", \"sad\"],\n",
    "    # Margarida\n",
    "    # [\"fear\", \"sad\", \"happy\"],\n",
    "    # [\"happy\", \"angry\", \"neutral\"],\n",
    "    # [\"fear\", \"angry\", \"surprise\"],\n",
    "    # [\"fear\", \"angry\", \"surprise\", \"neutral\"],\n",
    "    \n",
    "]\n",
    "iterationsGroup = [1500]\n",
    "hiddenLayersGroup = [\n",
    "    [20],\n",
    "    [144],\n",
    "    [144, 144],\n",
    "    [300,200,100,50],\n",
    "    [300,100,100,100],\n",
    "]\n",
    "batchSize = 128\n",
    "hyperParametersGroup = [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(labels, pred, y):\n",
    "    \n",
    "    confusionTFPN = {}\n",
    "    confusionLabels = {}\n",
    "    \n",
    "    # Foreach emotion\n",
    "    for ie in range(len(labels)):\n",
    "        # TRUE AND FALSE POSITIVES AND NEGATIVES (TFPN)\n",
    "        \n",
    "        # Get indexes where emotion was predicted\n",
    "        ieIndexesPred = [i for i in range(pred.size) if pred[i]==ie]\n",
    "        ieIndexesNotPred = [i for i in range(pred.size) if pred[i]!=ie]\n",
    "\n",
    "        # Predicted, and Actual\n",
    "        TP = sum(pred[:,np.newaxis][ieIndexesPred]==y[ieIndexesPred])\n",
    "        # Predicted, but not actual\n",
    "        FP = sum(pred[:,np.newaxis][ieIndexesPred]!=y[ieIndexesPred])\n",
    "        # Not predicted, but actual\n",
    "        FN = sum(y[ieIndexesNotPred]==ie)\n",
    "        # Not predicted and not actual\n",
    "        TN = sum(y[ieIndexesNotPred]!=ie)\n",
    "\n",
    "        TP = TP[0] if TP else 0\n",
    "        FP = FP[0] if FP else 0\n",
    "        FN = FN[0] if FN else 0\n",
    "        TN = TN[0] if TN else 0\n",
    "        \n",
    "        confusionTFPN[labels[ie]] = {\n",
    "            'TP': TP,\n",
    "            'FP': FP,\n",
    "            'FN': FN,\n",
    "            'TN': TN\n",
    "        }\n",
    "        \n",
    "        # CONFUSION WITH OTHER labels (Confusion)\n",
    "        # For emotion e\n",
    "        # Count the number of predictions made for all classes\n",
    "        # Foreach emotion, check how many times it has been predicted \n",
    "        \n",
    "        # Get indexes where emotion is real\n",
    "        ieIndexesY = [i for i in range(y.size) if y[i]==ie]\n",
    "        \n",
    "        # Foreach matching prediction, check what emotion was predicted\n",
    "        confusionLabels[labels[ie]] = {\n",
    "            e: sum(pred[:,np.newaxis][ieIndexesY]==labels.index(e))[0] for e in labels\n",
    "        }\n",
    "        \n",
    "    return confusionTFPN, confusionLabels\n",
    "\n",
    "def outputConfusionTables(labels, testExamplesNumber, confusionTFPN, confusionLabels, axs, axsLine, axsTitle):\n",
    "     # TABLES\n",
    "    rows = tuple(labels)\n",
    "    \n",
    "    # TABLES / TFPN\n",
    "    # Output confusion matrix as plot table\n",
    "    data = [\n",
    "        [\n",
    "            f\"{vals['TP']} ({vals['TP']/testExamplesNumber*100 if vals['TP'] else 0:.2f}%)\",\n",
    "            f\"{vals['TN']} ({vals['TN']/testExamplesNumber*100 if vals['TP'] else 0:.2f}%)\",\n",
    "            f\"{vals['TP']+vals['TN']} ({(vals['TP']+vals['TN'])/testExamplesNumber*100 if vals['TP']+vals['TN'] else 0:.2f}%)\",\n",
    "            f\"{vals['FP']} ({vals['FP']/testExamplesNumber*100 if vals['FP'] else 0:.2f}%)\",\n",
    "            f\"{vals['FN']} ({vals['FN']/testExamplesNumber*100 if vals['FN'] else 0:.2f}%)\",\n",
    "            f\"{vals['FP']+vals['FN']} ({(vals['FP']+vals['FN'])/testExamplesNumber*100 if vals['FP']+vals['FN'] else 0:.2f}%)\",\n",
    "            vals['FP']+vals['FN']+vals['TP']+vals['TN']\n",
    "        ]\n",
    "        for _, vals in confusionTFPN.items()\n",
    "    ]\n",
    "    columns = ['TP (%)', 'TN (%)', 'T (%)', 'FP (%)', 'FN (%)', 'F (%)', f\"Total\"]\n",
    "    \n",
    "    # Colorize cells depending on value\n",
    "    cellColoursTF=plt.cm.Blues([\n",
    "        [ (vals['TP']+vals['TN'])/testExamplesNumber, (vals['FP']+vals['FN'])/testExamplesNumber ] for _, vals in confusionTFPN.items()\n",
    "    ])\n",
    "    cellColourPos=plt.cm.Greens([\n",
    "        [ vals['TP']/(vals['TP']+vals['FP']) if vals['TP']+vals['FP'] else 0, vals['FP']/(vals['TP']+vals['FP']) if vals['TP']+vals['FP'] else 0 ] for _, vals in confusionTFPN.items()\n",
    "    ])\n",
    "    cellColourNeg=plt.cm.Reds([\n",
    "        [ vals['TN']/(vals['TN']+vals['FN']) if vals['TN']+vals['FN'] else 0, vals['FN']/(vals['TN']+vals['FN']) if vals['TN']+vals['FN'] else 0 ] for _, vals in confusionTFPN.items()\n",
    "    ])\n",
    "    \n",
    "    cellColours = [\n",
    "        [\n",
    "            cellColourPos[i][0],\n",
    "            cellColourNeg[i][0],\n",
    "            cellColoursTF[i][0],\n",
    "            cellColourPos[i][1],\n",
    "            cellColourNeg[i][1],\n",
    "            cellColoursTF[i][1],\n",
    "            [0, 0, 0, 0]\n",
    "        ]\n",
    "        for i in range(len(rows))\n",
    "    ]\n",
    "        \n",
    "    the_table = axs[axsLine].table(\n",
    "      cellText=data,\n",
    "      rowLabels=rows,\n",
    "      colLabels=columns,\n",
    "      loc='center',\n",
    "      cellColours=cellColours\n",
    "    )\n",
    "    # the_table.scale(1.2, 1)\n",
    "    the_table.auto_set_font_size(False)\n",
    "    the_table.set_fontsize(20)\n",
    "    axs[axsLine].axis('off')\n",
    "    axs[axsLine].axis('tight')\n",
    "    axs[axsLine].set_title(f\"Confusion matrix {axsTitle}\", fontsize=20, pad=0)    \n",
    "    \n",
    "    # TABLES / Confusion    \n",
    "    # Output confusion matrix as plot table\n",
    "    data = [[o for _,o in others.items()] for _,others in confusionLabels.items()]\n",
    "    columns = rows\n",
    "    \n",
    "    # Colorize cells depending on value\n",
    "    vals = [o for _,others in confusionLabels.items() for _,o in others.items()]\n",
    "    normal = plt.Normalize(min(vals)-1, max(vals)+1)\n",
    "    cellColours=plt.cm.Blues(normal(data))\n",
    "        \n",
    "    the_table = axs[axsLine+1].table(\n",
    "      cellText=data,\n",
    "      rowLabels=rows,\n",
    "      colLabels=columns,\n",
    "      loc='center',\n",
    "      cellColours=cellColours\n",
    "    )\n",
    "    \n",
    "    the_table.set_fontsize(20)\n",
    "    # the_table.scale(1, 4)\n",
    "    axs[axsLine+1].axis('off')\n",
    "    axs[axsLine+1].axis('tight')\n",
    "    axs[axsLine+1].set_title(f\"True/Predicted {axsTitle}\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LABELS happy, neutral\n",
      "Loaded 2000 traing examples with 2 labels, each with 48 features (pixels).\n",
      "Loaded 400 dev examples.\n",
      "Loaded 400 test examples.\n",
      "\n",
      "20\n",
      "\n",
      "Building network for 1500 iterations and batch size of 128 and 1 hidden layers: 20...\n",
      "Without regularization!\n",
      "\n",
      "Epoch 1/1500\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 25070.1522 - accuracy: 0.4899 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 2/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6905 - accuracy: 0.4949 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 3/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.5065 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 4/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.4947 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 5/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6922 - accuracy: 0.4972 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
      "Epoch 6/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5037 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 7/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.5023 - val_loss: 0.6932 - val_accuracy: 0.4975\n",
      "Epoch 8/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.5045 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 9/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5109 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 10/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 11/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4841 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 12/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5069 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 13/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4961 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 14/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 15/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4934 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 16/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4989 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 17/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4832 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 18/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4732 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 19/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4842 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 20/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 21/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5082 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 22/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4884 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 23/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 24/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4830 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 25/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5286 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 26/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4959 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 27/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5134 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 28/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5149 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 29/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 30/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5101 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 31/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 32/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4821 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 33/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 34/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5197 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 35/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5072 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 36/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5084 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 37/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4798 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 38/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5074 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 39/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 40/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4898 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 41/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4790 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 42/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 43/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 44/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 45/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4984 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 46/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 47/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4849 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 48/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4946 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 49/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4748 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 50/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4784 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 51/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5106 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 52/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4864 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 53/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5034 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 54/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4836 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 55/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4920 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 56/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 57/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 58/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5048 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 59/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 60/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4945 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 61/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4917 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 62/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5006 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 63/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5079 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 64/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4895 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 65/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4959 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 66/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4895 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 67/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4944 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 68/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5081 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 69/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 70/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4791 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 71/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 72/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 73/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5059 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 74/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5038 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 75/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 76/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 77/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4915 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 78/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4945 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 79/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4851 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 80/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4916 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 81/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 82/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5102 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 83/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 84/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5022 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 85/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4782 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 86/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5068 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 87/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5056 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 88/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5007 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 89/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 90/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4733 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 91/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.4951 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 92/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4819 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 93/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4859 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 94/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4715 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 95/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5043 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 96/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4843 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 97/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4906 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 98/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4977 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 99/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 100/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 101/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5114 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 102/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5120 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 103/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4732 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 104/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 105/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4812 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 106/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5041 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 107/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5101 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 108/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4961 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 109/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4710 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 110/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 111/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4889 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 112/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5030 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 113/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4857 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 114/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4907 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 115/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4812 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 116/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5161 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 117/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 118/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4892 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 119/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5012 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 120/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5178 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 121/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4908 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 122/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5033 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 123/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5103 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 124/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5037 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 125/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5103 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 126/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4929 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 127/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5135 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 128/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4903 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 129/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4901 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 130/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4948 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 131/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5082 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 132/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4881 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 133/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.4984 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 134/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5031 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 135/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5058 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 136/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5085 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 137/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 138/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 139/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5004 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 140/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4920 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 141/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4628 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 142/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5117 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 143/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 144/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.4890 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 145/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 146/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5120 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 147/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4946 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 148/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4829 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 149/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5146 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 150/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4858 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 151/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4672 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 152/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4701 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 153/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4804 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 154/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5074 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 155/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5034 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 156/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4821 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 157/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5188 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 158/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4880 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 159/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4872 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 160/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5010 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 161/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5083 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 162/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5095 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 163/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5074 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 164/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5152 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 165/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4804 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 166/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 167/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 168/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 169/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4813 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 171/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4753 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 172/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4855 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 173/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 174/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5090 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 175/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 176/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 177/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4906 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 178/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 179/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5034 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 180/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4899 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 181/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 182/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5082 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 183/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4943 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 184/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5139 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 185/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5093 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 186/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5069 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 187/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 188/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 189/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4626 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 190/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4844 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 191/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.4914 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 192/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4840 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 193/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4915 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 194/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5233 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 195/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5029 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 196/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5125 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 197/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4910 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 198/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4942 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 199/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4854 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 200/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5076 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 201/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 202/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4796 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 203/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4833 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 204/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5054 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 205/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4703 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 206/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4942 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 207/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5225 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 208/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4917 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 209/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5060 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 210/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5073 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 211/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4677 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 212/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4824 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 213/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5006 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 214/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4820 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 215/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4691 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 216/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4890 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 217/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5059 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 218/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5151 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 219/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 220/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4871 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 221/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 222/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4854 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 223/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5175 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 224/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 225/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5056 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 226/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4875 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4688 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 228/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5117 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 229/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4902 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 230/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4807 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 231/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5069 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 232/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5163 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 233/1500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4858 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 234/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4869 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 235/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 236/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 237/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5109 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 238/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5194 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 239/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5020 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 240/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4843 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 241/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4866 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 242/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4708 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 243/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 244/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4854 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 245/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5028 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 246/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 247/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5111 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 248/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4730 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 249/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5010 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 250/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5109 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 251/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4806 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 252/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4730 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 253/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4963 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 254/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4999 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 255/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5190 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 256/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 257/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4912 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 258/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5063 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 259/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4888 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 260/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5109 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 261/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 262/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 263/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 264/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4803 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 265/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 266/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4908 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 267/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 268/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 269/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5033 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 270/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5022 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 271/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4984 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 272/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5116 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 273/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4824 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 274/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4762 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 275/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5063 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 276/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4819 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 277/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4699 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 278/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4889 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 279/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5151 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 280/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 281/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4674 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 282/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5030 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 283/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4910 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5036 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 285/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4618 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 286/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5144 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 287/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4909 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 288/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5017 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 289/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4825 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 290/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4887 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 291/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 292/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 293/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4914 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 294/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4852 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 295/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 296/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 297/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4641 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 298/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 299/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5165 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 300/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4864 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 301/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4740 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 302/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5086 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 303/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4735 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 304/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4989 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 305/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4848 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 306/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 307/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5056 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 308/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4712 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 309/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4876 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 310/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 311/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4946 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 312/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4771 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 313/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5306 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 314/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5244 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 315/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4681 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 316/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4869 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 317/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4764 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 318/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4818 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 319/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5007 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 320/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5026 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 321/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5185 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 322/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4869 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 323/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5101 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 324/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4869 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 325/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4867 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 326/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5148 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 327/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5105 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 328/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5217 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 329/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 330/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5248 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 331/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5040 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 332/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4914 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 333/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4771 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 334/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4811 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 335/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 336/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 337/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4835 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 338/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4874 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 339/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4890 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 340/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 342/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5034 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 343/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5035 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 344/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5085 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 345/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5023 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 346/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5107 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 347/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4852 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 348/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4863 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 349/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4740 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 350/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5097 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 351/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 352/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4483 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 353/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 354/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5164 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 355/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4847 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 356/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4732 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 357/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4772 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 358/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4915 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 359/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4784 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 360/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5115 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 361/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4871 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 362/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5018 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 363/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4528 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 364/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 365/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4876 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 366/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5104 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 367/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5107 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 368/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5011 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 369/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5058 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 370/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4944 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 371/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5196 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 372/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5059 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 373/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5167 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 374/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 375/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4881 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 376/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4893 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 377/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 378/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4763 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 379/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4690 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 380/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4944 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 381/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4795 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 382/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4819 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 383/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5063 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 384/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 385/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5098 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 386/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5189 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 387/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 388/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4941 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 389/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4944 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 390/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4849 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 391/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5135 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 392/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 393/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4893 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 394/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4949 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 395/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4787 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 396/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 397/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4877 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5173 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 399/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4769 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 400/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 401/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4799 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 402/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4860 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 403/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5023 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 404/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 405/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5050 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 406/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5065 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 407/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5020 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 408/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4918 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 409/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4835 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 410/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5230 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 411/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 412/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 413/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 414/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 415/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4847 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 416/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5055 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 417/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4999 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 418/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 419/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4676 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 420/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4668 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 421/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5033 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 422/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 423/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5054 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 424/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4937 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 425/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5051 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 426/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4794 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 427/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4849 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 428/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4949 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 429/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 430/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4754 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 431/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4856 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 432/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5094 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 433/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5006 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 434/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4741 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 435/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4696 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 436/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4909 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 437/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4918 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 438/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5123 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 439/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4930 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 440/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4859 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 441/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 442/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 443/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 444/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4622 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 445/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4890 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 446/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4867 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 447/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 448/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 449/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4877 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 450/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4941 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 451/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5018 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 452/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 453/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 454/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5133 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5101 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 456/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 457/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5224 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 458/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 459/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5034 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 460/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 461/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 462/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 463/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5048 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 464/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4961 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 465/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5030 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 466/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4943 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 467/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 468/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4779 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 469/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4961 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 470/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 471/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5059 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 472/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4701 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 473/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4896 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 474/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4897 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 475/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5059 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 476/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 477/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4790 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 478/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5138 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 479/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4849 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 480/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4953 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 481/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5094 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 482/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 483/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4704 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 484/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 485/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 486/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4876 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 487/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4929 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 488/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4899 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 489/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4957 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 490/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5017 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 491/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 492/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5079 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 493/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 494/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4903 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 495/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4882 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 496/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4937 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 497/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4964 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 498/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4871 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 499/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4897 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 500/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4932 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 501/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4929 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 502/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4792 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 503/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5101 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 504/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4824 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 505/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4942 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 506/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.4971 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 507/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4810 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 508/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4879 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 509/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5186 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 510/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5131 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 511/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4853 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 512/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4760 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 513/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4971 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 514/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 515/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 516/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5027 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 517/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 518/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5042 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 519/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 520/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4944 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 521/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 522/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4848 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 523/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4689 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 524/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5133 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 525/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4662 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 526/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4758 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 527/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4827 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 528/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5085 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 529/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4909 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 530/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4880 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 531/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 532/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4984 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 533/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4841 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 534/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5099 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 535/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5018 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 536/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4881 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 537/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 538/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4882 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 539/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5068 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 540/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 541/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 542/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 543/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4978 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 544/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 545/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5065 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 546/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4911 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 547/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 548/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5084 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 549/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5074 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 550/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5101 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 551/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4890 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 552/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4948 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 553/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5037 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 554/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5175 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 555/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4837 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 556/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5094 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 557/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5188 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 558/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 559/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4759 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 560/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4730 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 561/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5105 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 562/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4758 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 563/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4929 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 564/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4785 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 565/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4857 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 566/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5090 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 567/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5084 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 568/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5055 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 569/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4681 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 570/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4658 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 571/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5049 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 572/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4587 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 573/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4753 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 574/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4834 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 575/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4885 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 576/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4939 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 577/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 578/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4805 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 579/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5141 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 580/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5081 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 581/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5074 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 582/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.4898 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 583/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5103 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 584/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4841 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 585/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4791 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 586/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 587/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4920 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 588/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 589/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5168 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 590/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.4996 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 591/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5065 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 592/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4893 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 593/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4882 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 594/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 595/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4888 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 596/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5010 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 597/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4918 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 598/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4899 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 599/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4924 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 600/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 601/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4920 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 602/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5071 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 603/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4946 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 604/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4896 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 605/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4715 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 606/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.4944 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 607/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4732 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 608/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4870 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 609/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 610/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5042 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 611/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5092 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 612/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 613/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4896 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 614/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 615/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5081 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 616/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5049 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 617/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4890 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 618/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4736 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 619/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4861 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 620/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 621/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5007 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 622/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5077 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 623/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4772 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 624/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5072 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 625/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5159 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 626/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 627/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4927 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 628/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4939 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 629/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4857 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 630/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 631/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4911 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 632/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4953 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 633/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4907 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 634/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5084 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 635/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 636/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4895 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 637/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4962 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 638/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4774 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 639/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4841 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 640/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5018 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 641/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4833 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 642/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4803 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 643/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 644/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4888 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 645/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 646/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4576 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 647/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 648/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5174 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 649/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4880 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 650/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5026 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 651/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 652/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5054 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 653/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4792 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 654/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5048 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 655/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4836 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 656/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5072 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 657/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5036 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 658/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4898 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 659/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4928 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 660/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4964 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 661/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 662/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4522 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 663/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4784 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 664/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4745 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 665/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4777 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 666/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4778 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 667/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4901 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 668/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4951 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 669/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5262 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 670/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5061 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 671/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5110 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 672/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 673/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4701 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 674/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 675/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 676/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4953 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 677/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4957 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 678/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4882 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 679/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 680/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5023 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 681/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4929 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 682/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5065 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4852 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 684/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5001 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 685/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4989 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 686/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4949 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 687/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4943 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 688/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 689/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4805 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 690/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5031 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 691/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4820 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 692/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5086 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 693/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5006 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 694/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 695/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4791 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 696/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5032 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 697/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4765 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 698/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4794 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 699/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4891 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 700/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4880 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 701/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 702/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5076 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 703/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 704/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5041 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 705/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4661 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 706/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5052 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 707/1500\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6932 - accuracy: 0.4930 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 708/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 709/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 710/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4840 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 711/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5070 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 712/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4915 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 713/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5070 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 714/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5018 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 715/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4789 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 716/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4897 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 717/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5067 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 718/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4693 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 719/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 720/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4712 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 721/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5123 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 722/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5123 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 723/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5036 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 724/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4909 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 725/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5125 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 726/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4766 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 727/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5046 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 728/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5055 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 729/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4901 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 730/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 731/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4959 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 732/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4943 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 733/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 734/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 735/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4699 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 736/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4769 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 737/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5208 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 738/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4916 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 739/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4836 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 741/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4951 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 742/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4834 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 743/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5118 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 744/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4732 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 745/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5090 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 746/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4840 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 747/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4854 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 748/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4864 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 749/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5074 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 750/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4892 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 751/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4856 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 752/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 753/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4725 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 754/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4900 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 755/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5230 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 756/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5098 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 757/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5041 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 758/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5018 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 759/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4851 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 760/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4953 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 761/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 762/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4971 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 763/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4857 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 764/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5042 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 765/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4961 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 766/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5001 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 767/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4792 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 768/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5200 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 769/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 770/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4819 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 771/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4971 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 772/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5044 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 773/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4901 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 774/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5120 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 775/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4900 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 776/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4962 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 777/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5239 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 778/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5036 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 779/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4941 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 780/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5066 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 781/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 782/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4977 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 783/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4921 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 784/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4890 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 785/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4901 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 786/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4922 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 787/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4937 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 788/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4800 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 789/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4740 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 790/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5046 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 791/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4796 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 792/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5113 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 793/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4922 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 794/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5023 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 795/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4853 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 796/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5111 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 797/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.4956 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 798/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5037 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 799/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4769 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 800/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5011 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 801/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5282 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 802/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4921 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 803/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4803 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 804/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5006 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 805/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4898 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 806/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4914 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 807/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5043 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 808/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 809/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4818 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 810/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4989 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 811/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5041 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 812/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5007 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 813/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4919 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 814/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 815/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4964 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 816/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4720 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 817/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4861 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 818/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4591 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 819/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4929 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 820/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4945 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 821/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4778 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 822/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 823/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 824/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5124 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 825/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4829 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 826/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4746 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 827/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4806 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 828/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4880 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 829/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4904 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 830/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 831/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5180 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 832/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4849 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 833/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5205 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 834/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5084 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 835/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4790 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 836/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4850 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 837/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 838/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5055 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 839/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4885 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 840/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5078 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 841/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5079 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 842/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 843/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4962 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 844/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5102 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 845/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4820 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 846/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4999 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 847/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4928 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 848/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4797 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 849/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4918 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 850/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5073 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 851/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4909 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 852/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5077 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 853/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5130 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 854/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5022 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 855/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 856/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5114 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 857/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5028 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 858/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4744 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 859/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4816 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 860/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4944 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 861/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5026 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 862/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4932 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 863/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 864/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 865/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4791 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 866/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5036 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 867/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4827 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 868/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4850 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 869/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4882 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 870/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4739 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 871/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4649 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 872/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4826 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 873/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 874/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 875/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 876/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4922 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 877/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4875 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 878/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4798 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 879/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 880/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 881/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5022 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 882/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 883/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5049 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 884/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5065 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 885/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4826 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 886/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 887/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 888/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5086 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 889/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4854 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 890/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5045 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 891/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4851 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 892/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4807 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 893/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4899 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 894/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4898 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 895/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5039 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 896/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 897/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5166 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 898/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5026 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 899/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4915 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 900/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4963 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 901/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5042 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 902/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 903/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4773 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 904/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5123 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 905/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4942 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 906/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4752 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 907/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5093 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 908/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5006 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 909/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4607 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 910/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5082 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 911/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5111 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 912/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4823 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 913/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 914/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4834 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 915/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 916/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4808 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 917/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5159 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 918/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5184 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 919/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5037 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 920/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4913 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 921/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5168 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 922/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 923/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4957 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 924/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 925/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 926/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4945 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 927/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4910 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 928/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4818 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 929/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4939 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 930/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4904 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 931/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5109 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 932/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4774 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 933/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4685 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 934/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 935/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5074 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 936/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4797 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 937/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4500 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 938/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 939/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 940/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4733 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 941/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 942/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4864 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 943/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5083 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 944/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 945/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 946/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4787 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 947/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5001 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 948/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5061 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 949/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4817 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 950/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4628 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 951/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4870 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 952/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5046 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 953/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5068 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 954/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4848 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 955/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4959 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 956/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4754 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 957/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4579 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 958/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5033 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 959/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4895 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 960/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 961/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 962/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5153 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 963/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5067 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 964/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4821 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 965/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 966/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 967/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 968/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4701 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 969/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4897 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 970/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5077 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 971/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4694 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 972/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4728 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 973/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5113 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 974/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4864 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 975/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4917 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 976/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5106 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 977/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5152 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 978/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4922 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 979/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4819 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 980/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 981/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5043 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 982/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 983/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4946 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 984/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4864 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 985/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4921 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 986/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 987/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 988/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5105 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 989/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5033 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 990/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5089 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 991/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4760 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 992/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4918 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 993/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4875 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 994/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4821 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 995/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5024 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 996/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4932 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 997/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4891 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 998/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 999/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4870 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1000/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5035 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1001/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1002/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1003/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1004/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4723 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1005/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5120 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1006/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5096 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1007/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4906 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1008/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5040 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1009/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4824 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1010/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5100 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1011/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4760 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1012/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1013/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4939 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1014/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1015/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5074 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1016/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4858 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1017/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5126 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1018/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4821 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1019/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4732 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1020/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5054 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1021/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5085 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1022/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4927 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1023/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1024/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4984 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1025/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5018 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1026/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1027/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5014 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1028/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4729 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1029/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4926 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1030/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4556 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1031/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1032/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4941 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1033/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1034/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4906 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1035/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4842 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1036/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5020 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1037/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4944 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1038/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4888 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1039/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4873 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1040/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4937 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1041/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4903 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1042/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4989 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1043/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1044/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4894 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1045/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5099 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1046/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5014 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1047/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5022 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1048/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1049/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4911 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1050/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1051/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5024 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1052/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4948 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1053/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4907 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1054/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4924 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1055/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4894 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1056/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5084 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1057/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5015 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1058/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4726 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1059/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4859 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1060/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5024 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1061/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4850 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1062/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4941 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1063/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1064/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5181 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1065/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5178 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1066/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1067/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1068/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5024 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1069/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4928 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1070/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4924 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1071/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1072/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5109 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1073/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1074/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4715 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1075/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1076/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4927 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1077/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4626 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1078/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1079/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5017 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1080/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4717 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1081/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1082/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4604 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1083/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1084/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4794 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1085/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4871 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1086/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5112 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1087/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4906 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1088/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4691 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1089/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1090/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5059 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1091/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4869 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1092/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1093/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4795 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1094/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1095/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4758 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1096/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4873 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1097/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5079 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1098/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4689 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1099/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4799 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1100/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1101/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1102/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1103/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4868 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1104/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5113 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1105/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4906 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1106/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5035 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1107/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4873 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1108/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4917 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1109/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4868 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1110/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4951 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1111/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5087 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1112/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4712 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1113/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5118 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1114/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5063 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1115/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4953 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1116/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4776 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1117/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4869 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1118/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4837 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1119/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4865 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1120/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4957 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1121/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1122/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4944 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1123/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4637 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1124/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4836 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1125/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1126/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4905 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1127/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5044 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1128/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5034 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1129/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4767 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1130/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1131/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5103 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1132/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5157 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1133/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4897 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1134/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1135/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4944 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1136/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1137/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1138/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5175 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1139/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5017 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1140/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4904 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1141/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4724 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1142/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4708 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1143/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4746 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1144/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5041 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1145/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1146/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4876 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1147/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4884 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1148/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4951 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1149/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5172 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1150/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5119 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1151/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4866 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1152/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5177 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1153/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4984 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1154/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1155/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4777 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1156/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4756 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1157/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4853 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1158/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4795 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1159/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4729 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1160/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4857 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1161/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4837 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1162/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4798 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1163/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5201 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1164/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1165/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5061 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1166/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4720 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1167/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4926 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1168/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5032 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1169/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4887 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1170/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5081 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1171/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4932 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1172/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5067 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1173/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5049 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1174/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5117 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1175/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4932 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1176/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1177/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1178/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5095 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1179/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4882 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1180/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4826 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1181/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4855 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1182/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1183/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4959 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1184/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4885 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1185/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4957 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1186/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5102 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1187/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5101 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1188/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4978 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1189/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5097 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1190/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4962 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1191/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4873 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1192/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1193/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1194/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1195/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1196/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4867 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1197/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4961 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1198/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1199/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4812 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1200/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4874 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1201/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4692 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1202/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5046 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1203/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5089 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1204/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5185 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1205/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4961 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1206/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4720 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1207/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4963 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1208/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4753 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1209/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4893 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1210/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1211/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5043 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1212/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5127 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1213/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1214/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1215/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1216/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1217/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5025 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1218/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4889 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1219/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5115 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1220/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4765 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1221/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1222/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5212 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1223/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4920 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1224/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4863 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1225/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4919 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1226/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4865 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1227/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4781 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1228/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4998 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1229/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4886 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1230/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4984 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1231/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5102 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1232/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1233/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4957 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1234/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4937 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1235/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4774 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1236/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4849 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1237/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4660 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1238/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4862 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1239/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5054 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1240/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1241/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4916 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1242/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5291 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1243/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1244/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5223 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1245/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1246/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5063 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1247/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4917 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1248/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1249/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5056 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1250/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4687 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1251/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5124 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1252/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5135 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1253/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4687 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1254/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4885 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1255/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1256/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4875 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1257/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4936 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1258/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4901 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1259/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4720 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1260/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4971 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1261/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5131 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1262/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4919 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1263/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4914 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1264/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5033 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1265/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5183 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1266/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4883 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1267/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5096 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1268/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1269/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1270/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1271/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5125 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1272/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5069 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1273/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4843 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1274/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4915 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1275/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4914 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1276/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1277/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4807 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1278/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4890 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1279/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5001 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1280/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1281/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4733 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1282/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5132 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1283/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1284/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4813 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1285/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4845 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1286/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5085 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1287/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5007 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1288/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4937 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1289/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5139 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1290/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1291/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4841 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1292/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1293/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5090 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1294/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4806 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1295/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1296/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5028 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1297/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5014 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1298/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4926 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1299/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1300/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5068 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1301/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5108 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1302/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5020 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1303/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4880 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1304/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4756 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1305/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1306/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4821 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1307/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1308/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5131 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1309/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4821 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1310/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4894 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1311/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4879 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1312/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5071 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1313/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5033 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1314/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1315/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4937 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1316/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1317/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1318/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5111 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1319/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5026 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1320/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4864 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1321/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5049 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1322/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4989 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1323/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5157 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1324/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4824 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1325/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4890 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1326/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4904 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1327/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5084 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1328/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4870 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1329/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4886 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1330/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5042 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1331/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4927 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1332/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4899 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1333/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4812 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1334/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5076 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1335/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5023 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1336/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5062 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1337/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4791 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1338/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4808 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1339/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5083 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1340/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1341/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4912 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1342/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5050 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1343/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1344/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4927 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1345/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4837 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1346/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4719 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1347/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1348/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4977 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1349/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5107 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1350/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4834 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1351/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4826 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1352/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5082 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1353/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4853 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1354/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1355/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5062 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1356/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4568 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1357/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5020 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1358/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4757 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1359/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4806 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1360/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4808 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1361/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1362/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1363/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1364/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5044 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1365/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5055 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1366/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5129 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1367/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4889 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1368/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4856 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1369/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5177 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1370/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5050 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1371/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4911 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1372/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1373/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5026 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1374/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4885 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1375/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4971 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1376/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4796 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1377/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4846 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1378/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5101 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1379/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4906 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1380/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4728 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1381/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4865 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1382/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1383/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5032 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1384/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4962 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1385/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1386/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4780 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1387/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1388/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5017 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1389/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4786 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1390/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4927 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1391/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4934 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1392/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4905 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1393/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5030 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1394/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4898 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1395/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5105 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1396/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4832 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1397/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5076 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1398/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4686 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1399/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5152 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1400/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1401/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1402/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5023 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1403/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4869 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1404/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1405/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5022 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1406/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4913 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1407/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4910 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1408/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1409/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4899 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1410/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5121 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1411/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1412/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5034 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1413/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4845 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1414/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4831 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1415/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5118 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1416/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5147 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1417/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4896 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1418/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4906 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1419/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4927 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1420/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5017 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1421/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4953 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1422/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4680 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1423/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1424/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1425/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4760 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1426/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4912 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1427/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4953 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1428/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5087 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1429/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4962 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1430/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5011 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1431/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1432/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5033 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1433/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5009 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1434/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4810 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1435/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5137 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1436/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4937 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1437/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4844 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1438/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4879 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1439/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5031 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1440/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1441/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4816 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1442/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5155 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1443/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5030 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1444/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4767 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1445/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5279 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1446/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4915 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1447/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4806 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1448/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5026 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1449/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4777 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1450/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4895 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1451/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4854 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1452/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5072 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1453/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5052 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1454/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5077 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1455/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5139 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1456/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4839 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1457/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4691 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1458/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5130 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1459/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4738 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1460/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4778 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1461/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4776 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1462/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4872 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1463/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4936 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1464/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5067 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1465/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1466/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4822 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1467/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5046 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1468/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4723 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1469/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1470/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5174 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1471/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4934 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1472/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4902 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1473/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4968 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1474/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4831 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1475/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4835 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1476/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4754 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1477/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4936 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1478/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5127 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1479/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5132 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1480/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5024 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1481/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4888 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1482/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4922 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1483/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5134 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1484/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1485/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5230 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1486/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1487/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5129 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1488/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4886 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1489/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5077 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1490/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5073 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1491/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4779 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1492/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4781 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1493/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4756 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1494/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1495/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1496/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5068 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1497/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1498/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5108 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1499/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4779 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 1500/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4885 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "\n",
      "Model trained and metrics saved to ./metrics/happy_neutral/archive/1500iter_128batchS_0hyper_1hlayers__20/!\n",
      "20\n",
      "\n",
      "Building network for 1500 iterations and batch size of 128 and 1 hidden layers: 20...\n",
      "With regularization!\n",
      "\n",
      "Epoch 1/1500\n",
      "16/16 [==============================] - 1s 14ms/step - loss: 24147.2159 - accuracy: 0.4811 - val_loss: 0.6931 - val_accuracy: 0.5025\n",
      "Epoch 2/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4887 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 3/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4878 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 4/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 5/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.4978 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 6/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5195 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 7/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.4693 - val_loss: 0.6934 - val_accuracy: 0.4975\n",
      "Epoch 8/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.4981 - val_loss: 0.6935 - val_accuracy: 0.4975\n",
      "Epoch 9/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5105 - val_loss: 0.6931 - val_accuracy: 0.5025\n",
      "Epoch 10/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4968 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 11/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6930 - accuracy: 0.5016 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 12/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6926 - accuracy: 0.5179 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 13/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4909 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 14/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5115 - val_loss: 0.6933 - val_accuracy: 0.4975\n",
      "Epoch 15/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6926 - accuracy: 0.4862 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 16/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6980 - accuracy: 0.4884 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 17/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4762 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 18/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5026 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 19/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5082 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 20/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4863 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 21/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5141 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 22/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5120 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 23/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5042 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 24/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5151 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 25/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4833 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 26/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5116 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 27/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5068 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4880 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 29/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4818 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 30/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4951 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 31/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4876 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 32/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5082 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 33/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5141 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 34/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4953 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 35/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4660 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 36/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4926 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 37/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4716 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 38/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4720 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 39/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5018 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 40/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 41/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5074 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 42/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5178 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 43/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4828 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 44/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5106 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 45/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 46/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5074 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 47/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4951 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 48/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4820 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 49/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5089 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 50/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4944 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 51/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 52/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5049 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 53/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5014 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 54/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5181 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 55/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 56/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4905 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 57/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4934 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 58/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4848 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 59/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5092 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 60/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5106 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 61/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4829 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 62/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5139 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 63/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4735 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 64/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5081 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 65/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4787 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 66/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4964 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 67/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4870 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 68/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5178 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 69/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5031 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 70/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4761 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 71/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5056 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 72/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5007 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 73/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4849 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 74/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5158 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 75/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4937 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 76/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4818 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 77/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 78/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5076 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 79/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4634 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 80/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5081 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 81/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5094 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 82/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 83/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5160 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 84/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 85/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4977 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 86/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4815 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 87/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4699 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 88/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5134 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 89/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 90/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5110 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 91/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5100 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 92/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.4922 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 93/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5051 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 94/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5096 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 95/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4899 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 96/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5107 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 97/1500\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6932 - accuracy: 0.4733 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 98/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.4868 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 99/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 100/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4794 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 101/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 102/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5076 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 103/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4842 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 104/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.4953 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 105/1500\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.4902 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 106/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4937 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 107/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5032 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 108/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5275 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 109/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5094 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 110/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4906 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 111/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4770 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 112/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4798 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 113/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5002 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 114/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 115/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5033 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 116/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4934 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 117/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4804 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 118/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4707 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 119/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5142 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 120/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4706 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 121/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5066 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 122/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 123/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4951 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 124/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5100 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 125/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5091 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 126/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4891 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 127/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5126 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 128/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 129/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4928 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 130/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 131/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4870 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 132/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 133/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4876 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 134/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5034 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 135/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4873 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 136/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5122 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 137/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5031 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 138/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 139/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 140/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4861 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 141/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5018 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 142/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4899 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 143/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5098 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 144/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 145/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 146/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4676 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 147/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4748 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 148/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5052 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 149/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4816 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 150/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4871 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 151/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4962 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 152/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4853 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 153/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 154/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 155/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5130 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 156/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4700 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 157/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4746 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 158/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 159/1500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5069 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 160/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4888 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 161/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4711 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 162/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4872 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 163/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5094 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 164/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4883 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 165/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 166/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 167/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4871 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 168/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5115 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 169/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5059 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 170/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 171/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 172/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4943 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 173/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4916 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 174/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 175/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4906 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 176/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 177/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5100 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 178/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5051 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 179/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 180/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5077 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 181/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4934 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 182/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4891 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 183/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5107 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 184/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 185/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5123 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 186/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5150 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 187/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5031 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 188/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5043 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 189/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4942 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 190/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4852 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 191/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5085 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 192/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 193/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 194/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4802 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 195/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4934 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 196/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5020 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 197/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4730 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 198/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4759 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 200/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5039 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 201/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4978 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 202/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5052 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 203/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4643 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 204/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4891 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 205/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5111 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 206/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4989 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 207/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.4916 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 208/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4977 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 209/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4849 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 210/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5161 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 211/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4895 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 212/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5036 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 213/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5067 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 214/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4928 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 215/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4889 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 216/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5134 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 217/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 218/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5032 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 219/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 220/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5037 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 221/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4848 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 222/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5020 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 223/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4856 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 224/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 225/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5055 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 226/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5163 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 227/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5124 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 228/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4886 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 229/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5006 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 230/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5138 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 231/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5001 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 232/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4946 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 233/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4633 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 234/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4926 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 235/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4757 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 236/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5095 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 237/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 238/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4810 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 239/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4888 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 240/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5089 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 241/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4971 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 242/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4928 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 243/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4732 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 244/1500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4868 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 245/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5176 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 246/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4760 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 247/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5162 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 248/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5020 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 249/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4957 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 250/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4813 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 251/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5097 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 252/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5018 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 253/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5225 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 254/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5067 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 255/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.4965 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256/1500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4788 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 257/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4805 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 258/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4891 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 259/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 260/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5188 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 261/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 262/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5159 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 263/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5163 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 264/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5033 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 265/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4920 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 266/1500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5161 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 267/1500\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 0.6931 - accuracy: 0.5859"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e06f1677d72d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;31m# Train the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 history = model.fit(\n\u001b[0m\u001b[1;32m    104\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m   \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m   return pack_sequence_as(\n\u001b[0m\u001b[1;32m    659\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mpack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msortable\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m   \"\"\"\n\u001b[0;32m--> 579\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m     final_index, packed = _packed_nest_with_indices(structure, flat_sequence,\n\u001b[0m\u001b[1;32m    532\u001b[0m                                                     0, is_seq, sequence_fn)\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_index\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_packed_nest_with_indices\u001b[0;34m(structure, flat, index, is_seq, sequence_fn)\u001b[0m\n\u001b[1;32m    491\u001b[0m   \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m   \u001b[0msequence_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_fn\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sequence_like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_yield_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m       new_index, child = _packed_nest_with_indices(s, flat, index, is_seq,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_yield_value\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_yield_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_yield_sorted_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32myield\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_yield_sorted_items\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;31m# corresponding `OrderedDict` to pack it back).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_sorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m       \u001b[0;32myield\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0m_is_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_get_attrs_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### IMPORT LIBRARIES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#to load matlab mat files\n",
    "from scipy.io import loadmat\n",
    "# for saving metrics\n",
    "import os \n",
    "import json\n",
    "# for neural network\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "if not os.path.exists('./metrics'):\n",
    "    os.makedirs('./metrics')\n",
    "\n",
    "# FOR EACH LABEL GROUP\n",
    "for labelNames in labelsGroup:\n",
    "    # LOAD FILES\n",
    "    print(\"\\n\\nLABELS\", ', '.join(labelNames))\n",
    "\n",
    "    # Load Training/Dev/Test data\n",
    "    mat=loadmat(f\"../datasets/train/{'_'.join(labelNames)}.mat\")\n",
    "    X, y = mat[\"X\"], mat[\"y\"]\n",
    "    matDev=loadmat(f\"../datasets/dev/{'_'.join(labelNames)}.mat\")\n",
    "    X_valid, y_valid = matDev[\"X\"], matDev[\"y\"]\n",
    "    matTest=loadmat(f\"../datasets/test/{'_'.join(labelNames)}.mat\")\n",
    "    X_test, y_test = matTest[\"X\"], matTest[\"y\"]\n",
    "    \n",
    "    # NUMBERS\n",
    "    m = X.shape[0] # number of training examples\n",
    "    labels = np.max(y)+1 # number of labels\n",
    "    features = X.shape[1] # number of features per example\n",
    "\n",
    "    # Output user feedback\n",
    "    print(f\"Loaded {m} traing examples with {labels} labels, each with {features} features (pixels).\")\n",
    "    print(f\"Loaded {X_valid.shape[0]} dev examples.\")\n",
    "    print(f\"Loaded {X_test.shape[0]} test examples.\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Create folder for metrics\n",
    "    labelFolder = f\"./metrics/{'_'.join(labelNames)}\"\n",
    "    if not os.path.exists(labelFolder):\n",
    "        os.makedirs(labelFolder)\n",
    "    if not os.path.exists(f\"{labelFolder}/history\"):\n",
    "        os.makedirs(f\"{labelFolder}/history\")\n",
    "    if not os.path.exists(f\"{labelFolder}/predict\"):\n",
    "        os.makedirs(f\"{labelFolder}/predict\")\n",
    "    if not os.path.exists(f\"{labelFolder}/archive\"):\n",
    "        os.makedirs(f\"{labelFolder}/archive\")\n",
    "    \n",
    "    # FOREACH HIDDEN LAYER\n",
    "    for hiddenLayers in hiddenLayersGroup:\n",
    "        # FOR EACH HYPER PARAMETER\n",
    "        for hyperParameter in hyperParametersGroup:\n",
    "            # FOR EACH ITERATION NUMBER\n",
    "            for iterations in iterationsGroup:\n",
    "                \n",
    "                hiddenLayersText = '_'.join(map(str, hiddenLayers)) if len(hiddenLayers)>1 else hiddenLayers[0]\n",
    "                print(hiddenLayersText)\n",
    "                combinationName = f\"{iterations}iter_{batchSize}batchS_{hyperParameter}hyper_{len(hiddenLayers)}hlayers__{hiddenLayersText}\"\n",
    "                folder = f\"{labelFolder}/archive/{combinationName}/\"\n",
    "                if not os.path.exists(folder):\n",
    "                    os.makedirs(folder)\n",
    "\n",
    "                print(f\"\\nBuilding network for {iterations} iterations and batch size of {batchSize} and {len(hiddenLayers)} hidden layers: {hiddenLayersText}...\")\n",
    "                print(\"With regularization!\" if hyperParameter else \"Without regularization!\")\n",
    "                print()\n",
    "\n",
    "                # BUILD NETWORK\n",
    "                # Create model\n",
    "                modelSeq = []\n",
    "                # Flattens each image (48x48) to 1x2304\n",
    "                modelSeq.append(keras.layers.Flatten(input_shape = [2304]))\n",
    "                # Hidden layers with relu activation function\n",
    "                for h in hiddenLayers:                        \n",
    "                    modelSeq.append(keras.layers.Dense(\n",
    "                        h, \n",
    "                        activation = \"relu\", \n",
    "                        bias_regularizer= keras.regularizers.l2(hyperParameter) if hyperParameter else None\n",
    "                    ))\n",
    "                # Output layer with softmax activation function\n",
    "                modelSeq.append(keras.layers.Dense(\n",
    "                    labels, \n",
    "                    activation = \"softmax\",\n",
    "                    bias_regularizer= keras.regularizers.l2(hyperParameter) if hyperParameter else None\n",
    "                ))\n",
    "\n",
    "                model = keras.models.Sequential(modelSeq)\n",
    "\n",
    "                # Compile model\n",
    "                model.compile(\n",
    "                    # Using sparse categorical crossentropy loss function\n",
    "                    loss = \"sparse_categorical_crossentropy\",\n",
    "                    # Using stochastic gradient descent as gradient descent\n",
    "                    optimizer = \"sgd\",\n",
    "                    # In addition to cost, we want accuracy to help understanding how the model is working \n",
    "                    metrics = [\"accuracy\"]\n",
    "                )\n",
    "\n",
    "                # Train the network\n",
    "                history = model.fit(\n",
    "                    X,\n",
    "                    y,\n",
    "                    epochs = iterations,\n",
    "                    batch_size = batchSize,\n",
    "                    validation_data = (X_valid, y_valid)\n",
    "                )\n",
    "\n",
    "                # METRICS (SAVE TO FILE)\n",
    "\n",
    "                # Model training history\n",
    "                with open(f\"{folder}/history.json\", \"w\") as f:\n",
    "                    json.dump(history.history, f)\n",
    "\n",
    "                # Test model evaluation\n",
    "                with open(f\"{folder}/evaluation.json\", \"w\") as f:\n",
    "                    json.dump(model.evaluate(X_test, y_test, return_dict=True), f)\n",
    "\n",
    "                # Prediction for test data\n",
    "                with open(f\"{folder}/predict.json\", \"w\") as f:\n",
    "                    json.dump(model.predict(X_test).tolist(), f)\n",
    "\n",
    "                print(f\"\\nModel trained and metrics saved to {folder}!\")\n",
    "\n",
    "                # GENERATE GRAPHS AND SAVE TO FILE\n",
    "\n",
    "                # Model training history\n",
    "                pd.DataFrame(history.history).plot(figsize = (16, 10))\n",
    "                plt.grid(True)\n",
    "                plt.gca().set_ylim(0, 1)\n",
    "                plt.title(\"Neural network training metrics\")\n",
    "                plt.savefig(f\"{labelFolder}/history/{combinationName}.png\")\n",
    "\n",
    "                # Prediction for test data\n",
    "                predict = model.predict(X_test)\n",
    "                y_pred = np.array([np.argmax(p) for p in predict])\n",
    "                confusionTFPN, confusionLabels = confusionMatrix(labelNames, y_pred, y_test)\n",
    "                fig, axs = plt.subplots(2,1)\n",
    "                outputConfusionTables(labelNames, y_test.size, confusionTFPN, confusionLabels, axs, 0, \"WITHOUT regularization\")\n",
    "                fig.set_size_inches(18,6*len(labelNames))\n",
    "                fig.subplots_adjust(left=0.2, top=20)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f\"{labelFolder}/predict/{combinationName}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
