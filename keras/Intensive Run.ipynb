{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Intensive Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions\n",
    "1. Define the global variables;\n",
    "2. Run the second snippet. It builds the network and saves the output to a folder displayed on the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "labelsGroup = [\n",
    "    [\"angry\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"],\n",
    "    [\"happy\", \"sad\"],\n",
    "]\n",
    "iterationsGroup = [1000, 2500, 5000]\n",
    "hiddenLayersGroup = [\n",
    "    [144],\n",
    "    [300,200,100,50],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(labels, pred, y):\n",
    "    \n",
    "    confusionTFPN = {}\n",
    "    confusionLabels = {}\n",
    "    \n",
    "    # Foreach emotion\n",
    "    for ie in range(len(labels)):\n",
    "        # TRUE AND FALSE POSITIVES AND NEGATIVES (TFPN)\n",
    "        \n",
    "        # Get indexes where emotion was predicted\n",
    "        ieIndexesPred = [i for i in range(pred.size) if pred[i]==ie]\n",
    "        ieIndexesNotPred = [i for i in range(pred.size) if pred[i]!=ie]\n",
    "\n",
    "        # Predicted, and Actual\n",
    "        TP = sum(pred[:,np.newaxis][ieIndexesPred]==y[ieIndexesPred])\n",
    "        # Predicted, but not actual\n",
    "        FP = sum(pred[:,np.newaxis][ieIndexesPred]!=y[ieIndexesPred])\n",
    "        # Not predicted, but actual\n",
    "        FN = sum(y[ieIndexesNotPred]==ie)\n",
    "        # Not predicted and not actual\n",
    "        TN = sum(y[ieIndexesNotPred]!=ie)\n",
    "\n",
    "        TP = TP[0] if TP else 0\n",
    "        FP = FP[0] if FP else 0\n",
    "        FN = FN[0] if FN else 0\n",
    "        TN = TN[0] if TN else 0\n",
    "        \n",
    "        confusionTFPN[labels[ie]] = {\n",
    "            'TP': TP,\n",
    "            'FP': FP,\n",
    "            'FN': FN,\n",
    "            'TN': TN\n",
    "        }\n",
    "        \n",
    "        # CONFUSION WITH OTHER labels (Confusion)\n",
    "        # For emotion e\n",
    "        # Count the number of predictions made for all classes\n",
    "        # Foreach emotion, check how many times it has been predicted \n",
    "        \n",
    "        # Get indexes where emotion is real\n",
    "        ieIndexesY = [i for i in range(y.size) if y[i]==ie]\n",
    "        \n",
    "        # Foreach matching prediction, check what emotion was predicted\n",
    "        confusionLabels[labels[ie]] = {\n",
    "            e: sum(pred[:,np.newaxis][ieIndexesY]==labels.index(e))[0] for e in labels\n",
    "        }\n",
    "        \n",
    "    return confusionTFPN, confusionLabels\n",
    "\n",
    "def outputConfusionTables(labels, testExamplesNumber, confusionTFPN, confusionLabels, axs, axsLine, axsTitle):\n",
    "     # TABLES\n",
    "    rows = tuple(labels)\n",
    "    \n",
    "    # TABLES / TFPN\n",
    "    # Output confusion matrix as plot table\n",
    "    data = [\n",
    "        [\n",
    "            f\"{vals['TP']} ({vals['TP']/testExamplesNumber*100:.2f}%)\",\n",
    "            f\"{vals['TN']} ({vals['TN']/testExamplesNumber*100:.2f}%)\",\n",
    "            f\"{vals['TP']+vals['TN']} ({(vals['TP']+vals['TN'])/testExamplesNumber*100:.2f}%)\",\n",
    "            f\"{vals['FP']} ({vals['FP']/testExamplesNumber*100:.2f}%)\",\n",
    "            f\"{vals['FN']} ({vals['FN']/testExamplesNumber*100:.2f}%)\",\n",
    "            f\"{vals['FP']+vals['FN']} ({(vals['FP']+vals['FN'])/testExamplesNumber*100:.2f}%)\",\n",
    "            vals['FP']+vals['FN']+vals['TP']+vals['TN']\n",
    "        ]\n",
    "        for _, vals in confusionTFPN.items()\n",
    "    ]\n",
    "    columns = ['TP (%)', 'TN (%)', 'T (%)', 'FP (%)', 'FN (%)', 'F (%)', f\"Total\"]\n",
    "    \n",
    "    # Colorize cells depending on value\n",
    "    cellColours=plt.cm.Blues([\n",
    "        [\n",
    "            vals['TP']/testExamplesNumber,\n",
    "            vals['TN']/testExamplesNumber,\n",
    "            0,\n",
    "            vals['FP']/testExamplesNumber,\n",
    "            vals['FN']/testExamplesNumber,\n",
    "            0,\n",
    "            0\n",
    "        ]\n",
    "        for _, vals in confusionTFPN.items()\n",
    "    ])\n",
    "        \n",
    "    the_table = axs[axsLine].table(\n",
    "      cellText=data,\n",
    "      rowLabels=rows,\n",
    "      colLabels=columns,\n",
    "      loc='center',\n",
    "      cellColours=cellColours\n",
    "    )\n",
    "    # the_table.scale(1.2, 1)\n",
    "    the_table.auto_set_font_size(False)\n",
    "    the_table.set_fontsize(20)\n",
    "    axs[axsLine].axis('off')\n",
    "    axs[axsLine].axis('tight')\n",
    "    axs[axsLine].set_title(f\"Confusion matrix {axsTitle}\", fontsize=20, pad=0)    \n",
    "    \n",
    "    # TABLES / Confusion    \n",
    "    # Output confusion matrix as plot table\n",
    "    data = [[o for _,o in others.items()] for _,others in confusionLabels.items()]\n",
    "    columns = rows\n",
    "    \n",
    "    # Colorize cells depending on value\n",
    "    vals = [o for _,others in confusionLabels.items() for _,o in others.items()]\n",
    "    normal = plt.Normalize(min(vals)-1, max(vals)+1)\n",
    "    cellColours=plt.cm.Blues(normal(data))\n",
    "        \n",
    "    the_table = axs[axsLine+1].table(\n",
    "      cellText=data,\n",
    "      rowLabels=rows,\n",
    "      colLabels=columns,\n",
    "      loc='center',\n",
    "      cellColours=cellColours\n",
    "    )\n",
    "    \n",
    "    the_table.set_fontsize(20)\n",
    "    # the_table.scale(1, 4)\n",
    "    axs[axsLine+1].axis('off')\n",
    "    axs[axsLine+1].axis('tight')\n",
    "    axs[axsLine+1].set_title(f\"True/Predicted {axsTitle}\", fontsize=20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LABELS happy, sad\n",
      "Loaded 2000 traing examples with 2 labels, each with 2304 features (pixels).\n",
      "Loaded 400 dev examples.\n",
      "Loaded 400 test examples.\n",
      "\n",
      "\n",
      "Building network for 1000 iterations and 1 hidden layers: 144...\n",
      "\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48, 48) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48, 48), dtype=tf.float32, name='flatten_11_input'), name='flatten_11_input', description=\"created by layer 'flatten_11_input'\"), but it was called on an input with incompatible shape (None, 2304).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48, 48) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48, 48), dtype=tf.float32, name='flatten_11_input'), name='flatten_11_input', description=\"created by layer 'flatten_11_input'\"), but it was called on an input with incompatible shape (None, 2304).\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.8472 - accuracy: 0.4930WARNING:tensorflow:Model was constructed with shape (None, 48, 48) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48, 48), dtype=tf.float32, name='flatten_11_input'), name='flatten_11_input', description=\"created by layer 'flatten_11_input'\"), but it was called on an input with incompatible shape (None, 2304).\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.8439 - accuracy: 0.4943 - val_loss: 0.8233 - val_accuracy: 0.5050\n",
      "Epoch 2/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.5674 - val_loss: 0.6927 - val_accuracy: 0.5300\n",
      "Epoch 3/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.6006 - val_loss: 0.6199 - val_accuracy: 0.6775\n",
      "Epoch 4/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.6382 - val_loss: 0.6479 - val_accuracy: 0.5850\n",
      "Epoch 5/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.6457 - val_loss: 0.6364 - val_accuracy: 0.6225\n",
      "Epoch 6/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.6467 - val_loss: 0.6100 - val_accuracy: 0.6475\n",
      "Epoch 7/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6263 - accuracy: 0.6637 - val_loss: 0.5988 - val_accuracy: 0.7200\n",
      "Epoch 8/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6054 - accuracy: 0.6916 - val_loss: 0.5983 - val_accuracy: 0.7100\n",
      "Epoch 9/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.6749 - val_loss: 0.6778 - val_accuracy: 0.5775\n",
      "Epoch 10/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.6659 - val_loss: 0.5840 - val_accuracy: 0.6750\n",
      "Epoch 11/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.6964 - val_loss: 0.5731 - val_accuracy: 0.6950\n",
      "Epoch 12/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6879 - val_loss: 0.5688 - val_accuracy: 0.7175\n",
      "Epoch 13/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.6982 - val_loss: 0.6017 - val_accuracy: 0.6650\n",
      "Epoch 14/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.7213 - val_loss: 0.5559 - val_accuracy: 0.7175\n",
      "Epoch 15/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.7203 - val_loss: 0.5624 - val_accuracy: 0.7375\n",
      "Epoch 16/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7126 - val_loss: 0.6513 - val_accuracy: 0.6025\n",
      "Epoch 17/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7321 - val_loss: 0.5537 - val_accuracy: 0.7100\n",
      "Epoch 18/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7343 - val_loss: 0.6296 - val_accuracy: 0.6475\n",
      "Epoch 19/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7206 - val_loss: 0.5777 - val_accuracy: 0.7050\n",
      "Epoch 20/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7371 - val_loss: 0.6718 - val_accuracy: 0.6050\n",
      "Epoch 21/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7321 - val_loss: 0.5971 - val_accuracy: 0.6675\n",
      "Epoch 22/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7538 - val_loss: 0.5780 - val_accuracy: 0.6725\n",
      "Epoch 23/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7312 - val_loss: 0.5610 - val_accuracy: 0.6725\n",
      "Epoch 24/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.7192 - val_loss: 0.5642 - val_accuracy: 0.6850\n",
      "Epoch 25/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7422 - val_loss: 0.5955 - val_accuracy: 0.6725\n",
      "Epoch 26/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7473 - val_loss: 0.5437 - val_accuracy: 0.7025\n",
      "Epoch 27/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7629 - val_loss: 0.5675 - val_accuracy: 0.7225\n",
      "Epoch 28/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7537 - val_loss: 0.5486 - val_accuracy: 0.6925\n",
      "Epoch 29/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7841 - val_loss: 0.5550 - val_accuracy: 0.7325\n",
      "Epoch 30/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7465 - val_loss: 0.5383 - val_accuracy: 0.7550\n",
      "Epoch 31/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7802 - val_loss: 0.5454 - val_accuracy: 0.6975\n",
      "Epoch 32/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7701 - val_loss: 0.5370 - val_accuracy: 0.7475\n",
      "Epoch 33/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7619 - val_loss: 0.5405 - val_accuracy: 0.6975\n",
      "Epoch 34/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7643 - val_loss: 0.6259 - val_accuracy: 0.6700\n",
      "Epoch 35/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7726 - val_loss: 0.5510 - val_accuracy: 0.6850\n",
      "Epoch 36/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4761 - accuracy: 0.7909 - val_loss: 0.5479 - val_accuracy: 0.7425\n",
      "Epoch 37/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7877 - val_loss: 0.5321 - val_accuracy: 0.7300\n",
      "Epoch 38/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7668 - val_loss: 0.5843 - val_accuracy: 0.7075\n",
      "Epoch 39/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7757 - val_loss: 0.5659 - val_accuracy: 0.7075\n",
      "Epoch 40/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7883 - val_loss: 0.7727 - val_accuracy: 0.5950\n",
      "Epoch 41/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7818 - val_loss: 0.5684 - val_accuracy: 0.6775\n",
      "Epoch 42/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8150 - val_loss: 0.5359 - val_accuracy: 0.7125\n",
      "Epoch 43/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7849 - val_loss: 0.6054 - val_accuracy: 0.7075\n",
      "Epoch 44/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7874 - val_loss: 0.7041 - val_accuracy: 0.6250\n",
      "Epoch 45/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7704 - val_loss: 0.5388 - val_accuracy: 0.7325\n",
      "Epoch 46/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7956 - val_loss: 0.5365 - val_accuracy: 0.7075\n",
      "Epoch 47/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.8127 - val_loss: 0.5365 - val_accuracy: 0.7300\n",
      "Epoch 48/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8037 - val_loss: 0.8357 - val_accuracy: 0.5750\n",
      "Epoch 49/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7766 - val_loss: 0.5480 - val_accuracy: 0.6975\n",
      "Epoch 50/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7898 - val_loss: 0.5385 - val_accuracy: 0.7125\n",
      "Epoch 51/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8205 - val_loss: 0.5530 - val_accuracy: 0.7475\n",
      "Epoch 52/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.8143 - val_loss: 0.5465 - val_accuracy: 0.7300\n",
      "Epoch 53/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8241 - val_loss: 0.5881 - val_accuracy: 0.6650\n",
      "Epoch 54/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8051 - val_loss: 0.6451 - val_accuracy: 0.6775\n",
      "Epoch 55/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7893 - val_loss: 0.5392 - val_accuracy: 0.7075\n",
      "Epoch 56/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8303 - val_loss: 0.5448 - val_accuracy: 0.7000\n",
      "Epoch 57/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8169 - val_loss: 0.5581 - val_accuracy: 0.7300\n",
      "Epoch 58/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8230 - val_loss: 0.6078 - val_accuracy: 0.7100\n",
      "Epoch 59/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8268 - val_loss: 0.5944 - val_accuracy: 0.7325\n",
      "Epoch 60/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8213 - val_loss: 0.5654 - val_accuracy: 0.7250\n",
      "Epoch 61/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8457 - val_loss: 0.6688 - val_accuracy: 0.6500\n",
      "Epoch 62/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8430 - val_loss: 0.5873 - val_accuracy: 0.7200\n",
      "Epoch 63/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8237 - val_loss: 0.5543 - val_accuracy: 0.7550\n",
      "Epoch 64/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8320 - val_loss: 0.5481 - val_accuracy: 0.7325\n",
      "Epoch 65/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3797 - accuracy: 0.8415 - val_loss: 0.5331 - val_accuracy: 0.7325\n",
      "Epoch 66/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3470 - accuracy: 0.8540 - val_loss: 0.5886 - val_accuracy: 0.6900\n",
      "Epoch 67/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3663 - accuracy: 0.8517 - val_loss: 0.5517 - val_accuracy: 0.7150\n",
      "Epoch 68/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8681 - val_loss: 0.9166 - val_accuracy: 0.5825\n",
      "Epoch 69/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8464 - val_loss: 0.5443 - val_accuracy: 0.7100\n",
      "Epoch 70/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8544 - val_loss: 0.6866 - val_accuracy: 0.6650\n",
      "Epoch 71/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3555 - accuracy: 0.8464 - val_loss: 0.5777 - val_accuracy: 0.7025\n",
      "Epoch 72/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8422 - val_loss: 0.5621 - val_accuracy: 0.7050\n",
      "Epoch 73/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8554 - val_loss: 0.6150 - val_accuracy: 0.7200\n",
      "Epoch 74/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8552 - val_loss: 0.5494 - val_accuracy: 0.7075\n",
      "Epoch 75/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.8533 - val_loss: 0.7163 - val_accuracy: 0.6900\n",
      "Epoch 76/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3547 - accuracy: 0.8474 - val_loss: 1.0148 - val_accuracy: 0.5650\n",
      "Epoch 77/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8342 - val_loss: 0.5821 - val_accuracy: 0.6925\n",
      "Epoch 78/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3225 - accuracy: 0.8633 - val_loss: 0.5535 - val_accuracy: 0.7250\n",
      "Epoch 79/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3150 - accuracy: 0.8824 - val_loss: 0.6127 - val_accuracy: 0.7275\n",
      "Epoch 80/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3216 - accuracy: 0.8730 - val_loss: 0.5565 - val_accuracy: 0.7075\n",
      "Epoch 81/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3364 - accuracy: 0.8582 - val_loss: 0.8755 - val_accuracy: 0.6275\n",
      "Epoch 82/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3756 - accuracy: 0.8432 - val_loss: 0.5427 - val_accuracy: 0.7100\n",
      "Epoch 83/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3154 - accuracy: 0.8704 - val_loss: 0.5639 - val_accuracy: 0.7325\n",
      "Epoch 84/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3132 - accuracy: 0.8673 - val_loss: 0.6793 - val_accuracy: 0.6750\n",
      "Epoch 85/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3108 - accuracy: 0.8807 - val_loss: 0.5868 - val_accuracy: 0.6950\n",
      "Epoch 86/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2888 - accuracy: 0.8887 - val_loss: 0.7243 - val_accuracy: 0.6475\n",
      "Epoch 87/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3418 - accuracy: 0.8622 - val_loss: 0.8922 - val_accuracy: 0.6150\n",
      "Epoch 88/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3367 - accuracy: 0.8461 - val_loss: 0.5854 - val_accuracy: 0.7025\n",
      "Epoch 89/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3002 - accuracy: 0.8731 - val_loss: 0.5712 - val_accuracy: 0.7250\n",
      "Epoch 90/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2833 - accuracy: 0.8906 - val_loss: 0.5691 - val_accuracy: 0.6975\n",
      "Epoch 91/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3242 - accuracy: 0.8623 - val_loss: 0.5685 - val_accuracy: 0.7100\n",
      "Epoch 92/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3063 - accuracy: 0.8873 - val_loss: 0.8567 - val_accuracy: 0.6150\n",
      "Epoch 93/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3127 - accuracy: 0.8755 - val_loss: 0.6804 - val_accuracy: 0.6575\n",
      "Epoch 94/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3507 - accuracy: 0.8419 - val_loss: 0.8471 - val_accuracy: 0.6550\n",
      "Epoch 95/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3768 - accuracy: 0.8329 - val_loss: 0.6510 - val_accuracy: 0.7000\n",
      "Epoch 96/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2830 - accuracy: 0.8944 - val_loss: 0.7861 - val_accuracy: 0.6875\n",
      "Epoch 97/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2970 - accuracy: 0.8685 - val_loss: 0.6641 - val_accuracy: 0.7225\n",
      "Epoch 98/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3024 - accuracy: 0.8618 - val_loss: 0.7268 - val_accuracy: 0.6950\n",
      "Epoch 99/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.3127 - accuracy: 0.8711 - val_loss: 1.1989 - val_accuracy: 0.5675\n",
      "Epoch 100/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3548 - accuracy: 0.8447 - val_loss: 0.5783 - val_accuracy: 0.7100\n",
      "Epoch 101/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2542 - accuracy: 0.9113 - val_loss: 0.6269 - val_accuracy: 0.6975\n",
      "Epoch 102/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.2599 - accuracy: 0.8987 - val_loss: 0.5782 - val_accuracy: 0.7375\n",
      "Epoch 103/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2634 - accuracy: 0.9044 - val_loss: 0.5740 - val_accuracy: 0.7075\n",
      "Epoch 104/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2838 - accuracy: 0.8796 - val_loss: 0.6002 - val_accuracy: 0.7325\n",
      "Epoch 105/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2365 - accuracy: 0.9149 - val_loss: 0.5902 - val_accuracy: 0.7425\n",
      "Epoch 106/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2414 - accuracy: 0.9078 - val_loss: 1.2283 - val_accuracy: 0.5725\n",
      "Epoch 107/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3193 - accuracy: 0.8863 - val_loss: 0.6096 - val_accuracy: 0.7325\n",
      "Epoch 108/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2333 - accuracy: 0.9119 - val_loss: 0.5857 - val_accuracy: 0.7075\n",
      "Epoch 109/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2177 - accuracy: 0.9322 - val_loss: 0.7417 - val_accuracy: 0.7125\n",
      "Epoch 110/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2566 - accuracy: 0.8996 - val_loss: 0.6076 - val_accuracy: 0.7150\n",
      "Epoch 111/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2258 - accuracy: 0.9291 - val_loss: 0.5861 - val_accuracy: 0.7300\n",
      "Epoch 112/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2297 - accuracy: 0.9149 - val_loss: 0.6025 - val_accuracy: 0.7125\n",
      "Epoch 113/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2463 - accuracy: 0.9104 - val_loss: 0.7605 - val_accuracy: 0.6550\n",
      "Epoch 114/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3173 - accuracy: 0.8728 - val_loss: 0.5912 - val_accuracy: 0.7275\n",
      "Epoch 115/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1959 - accuracy: 0.9360 - val_loss: 0.6992 - val_accuracy: 0.6775\n",
      "Epoch 116/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2199 - accuracy: 0.9210 - val_loss: 0.6059 - val_accuracy: 0.7150\n",
      "Epoch 117/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1921 - accuracy: 0.9384 - val_loss: 1.1230 - val_accuracy: 0.6025\n",
      "Epoch 118/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2716 - accuracy: 0.8887 - val_loss: 0.6288 - val_accuracy: 0.7400\n",
      "Epoch 119/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2030 - accuracy: 0.9353 - val_loss: 0.6199 - val_accuracy: 0.7125\n",
      "Epoch 120/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2535 - accuracy: 0.9019 - val_loss: 0.6134 - val_accuracy: 0.7250\n",
      "Epoch 121/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1934 - accuracy: 0.9383 - val_loss: 0.5987 - val_accuracy: 0.7225\n",
      "Epoch 122/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2209 - accuracy: 0.9277 - val_loss: 0.6125 - val_accuracy: 0.7150\n",
      "Epoch 123/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1941 - accuracy: 0.9424 - val_loss: 0.6906 - val_accuracy: 0.6925\n",
      "Epoch 124/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9360 - val_loss: 0.7915 - val_accuracy: 0.6875\n",
      "Epoch 125/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3132 - accuracy: 0.8730 - val_loss: 0.6686 - val_accuracy: 0.7000\n",
      "Epoch 126/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2002 - accuracy: 0.9321 - val_loss: 0.6935 - val_accuracy: 0.6675\n",
      "Epoch 127/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1936 - accuracy: 0.9468 - val_loss: 0.7627 - val_accuracy: 0.6875\n",
      "Epoch 128/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1890 - accuracy: 0.9450 - val_loss: 0.6288 - val_accuracy: 0.7125\n",
      "Epoch 129/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 0.9578 - val_loss: 0.9570 - val_accuracy: 0.6625\n",
      "Epoch 130/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8662 - val_loss: 0.6236 - val_accuracy: 0.7250\n",
      "Epoch 131/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1626 - accuracy: 0.9571 - val_loss: 0.6346 - val_accuracy: 0.7125\n",
      "Epoch 132/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2075 - accuracy: 0.9296 - val_loss: 0.6658 - val_accuracy: 0.6875\n",
      "Epoch 133/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1694 - accuracy: 0.9575 - val_loss: 0.6568 - val_accuracy: 0.7025\n",
      "Epoch 134/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1914 - accuracy: 0.9362 - val_loss: 1.2996 - val_accuracy: 0.5950\n",
      "Epoch 135/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2844 - accuracy: 0.8871 - val_loss: 0.6476 - val_accuracy: 0.7100\n",
      "Epoch 136/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1312 - accuracy: 0.9690 - val_loss: 0.6480 - val_accuracy: 0.6800\n",
      "Epoch 137/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1711 - accuracy: 0.9548 - val_loss: 0.6978 - val_accuracy: 0.6850\n",
      "Epoch 138/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9480 - val_loss: 0.6774 - val_accuracy: 0.6975\n",
      "Epoch 139/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1593 - accuracy: 0.9451 - val_loss: 0.6428 - val_accuracy: 0.7250\n",
      "Epoch 140/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1448 - accuracy: 0.9636 - val_loss: 1.1151 - val_accuracy: 0.6275\n",
      "Epoch 141/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1877 - accuracy: 0.9447 - val_loss: 0.6528 - val_accuracy: 0.7400\n",
      "Epoch 142/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1423 - accuracy: 0.9684 - val_loss: 0.6344 - val_accuracy: 0.6950\n",
      "Epoch 143/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1686 - accuracy: 0.9575 - val_loss: 0.7315 - val_accuracy: 0.6675\n",
      "Epoch 144/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1566 - accuracy: 0.9614 - val_loss: 0.6332 - val_accuracy: 0.7175\n",
      "Epoch 145/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9724 - val_loss: 0.7571 - val_accuracy: 0.6875\n",
      "Epoch 146/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1364 - accuracy: 0.9665 - val_loss: 0.7414 - val_accuracy: 0.7275\n",
      "Epoch 147/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1741 - accuracy: 0.9472 - val_loss: 0.6462 - val_accuracy: 0.7275\n",
      "Epoch 148/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1288 - accuracy: 0.9720 - val_loss: 0.7273 - val_accuracy: 0.7025\n",
      "Epoch 149/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1846 - accuracy: 0.9421 - val_loss: 0.8493 - val_accuracy: 0.6700\n",
      "Epoch 150/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.9176 - val_loss: 0.8668 - val_accuracy: 0.6750\n",
      "Epoch 151/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1750 - accuracy: 0.9393 - val_loss: 0.6917 - val_accuracy: 0.7300\n",
      "Epoch 152/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1147 - accuracy: 0.9732 - val_loss: 0.6870 - val_accuracy: 0.7200\n",
      "Epoch 153/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1853 - accuracy: 0.9333 - val_loss: 1.6321 - val_accuracy: 0.5600\n",
      "Epoch 154/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2052 - accuracy: 0.9429 - val_loss: 0.6828 - val_accuracy: 0.7350\n",
      "Epoch 155/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1216 - accuracy: 0.9707 - val_loss: 0.7044 - val_accuracy: 0.7200\n",
      "Epoch 156/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1253 - accuracy: 0.9667 - val_loss: 0.6939 - val_accuracy: 0.7175\n",
      "Epoch 157/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1191 - accuracy: 0.9730 - val_loss: 0.7939 - val_accuracy: 0.6775\n",
      "Epoch 158/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1465 - accuracy: 0.9555 - val_loss: 0.8712 - val_accuracy: 0.6600\n",
      "Epoch 159/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1682 - accuracy: 0.9479 - val_loss: 0.6905 - val_accuracy: 0.7250\n",
      "Epoch 160/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9669 - val_loss: 0.6542 - val_accuracy: 0.7150\n",
      "Epoch 161/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1248 - accuracy: 0.9737 - val_loss: 0.7687 - val_accuracy: 0.6925\n",
      "Epoch 162/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1351 - accuracy: 0.9589 - val_loss: 0.6934 - val_accuracy: 0.7275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1312 - accuracy: 0.9628 - val_loss: 0.7263 - val_accuracy: 0.7125\n",
      "Epoch 164/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0956 - accuracy: 0.9849 - val_loss: 0.7559 - val_accuracy: 0.7350\n",
      "Epoch 165/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1001 - accuracy: 0.9751 - val_loss: 0.7131 - val_accuracy: 0.7000\n",
      "Epoch 166/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.9843 - val_loss: 0.7246 - val_accuracy: 0.7400\n",
      "Epoch 167/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0877 - accuracy: 0.9839 - val_loss: 0.7199 - val_accuracy: 0.7175\n",
      "Epoch 168/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1043 - accuracy: 0.9786 - val_loss: 0.7165 - val_accuracy: 0.7350\n",
      "Epoch 169/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1195 - accuracy: 0.9686 - val_loss: 0.8094 - val_accuracy: 0.6525\n",
      "Epoch 170/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1088 - accuracy: 0.9804 - val_loss: 0.7177 - val_accuracy: 0.7350\n",
      "Epoch 171/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9670 - val_loss: 0.8109 - val_accuracy: 0.7225\n",
      "Epoch 172/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1088 - accuracy: 0.9708 - val_loss: 0.7297 - val_accuracy: 0.7400\n",
      "Epoch 173/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1102 - accuracy: 0.9682 - val_loss: 0.7663 - val_accuracy: 0.7400\n",
      "Epoch 174/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1004 - accuracy: 0.9746 - val_loss: 0.7634 - val_accuracy: 0.7375\n",
      "Epoch 175/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0944 - accuracy: 0.9805 - val_loss: 0.8237 - val_accuracy: 0.6900\n",
      "Epoch 176/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2194 - accuracy: 0.9312 - val_loss: 0.7323 - val_accuracy: 0.7075\n",
      "Epoch 177/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1037 - accuracy: 0.9778 - val_loss: 0.7500 - val_accuracy: 0.6975\n",
      "Epoch 178/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1120 - accuracy: 0.9673 - val_loss: 0.7237 - val_accuracy: 0.7425\n",
      "Epoch 179/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0793 - accuracy: 0.9885 - val_loss: 0.7359 - val_accuracy: 0.7275\n",
      "Epoch 180/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0805 - accuracy: 0.9826 - val_loss: 0.7546 - val_accuracy: 0.7225\n",
      "Epoch 181/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1047 - accuracy: 0.9695 - val_loss: 1.6690 - val_accuracy: 0.5750\n",
      "Epoch 182/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1739 - accuracy: 0.9469 - val_loss: 0.7353 - val_accuracy: 0.7300\n",
      "Epoch 183/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 0.9877 - val_loss: 0.7564 - val_accuracy: 0.7275\n",
      "Epoch 184/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0869 - accuracy: 0.9862 - val_loss: 0.8148 - val_accuracy: 0.7250\n",
      "Epoch 185/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0811 - accuracy: 0.9830 - val_loss: 0.7476 - val_accuracy: 0.7225\n",
      "Epoch 186/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0732 - accuracy: 0.9879 - val_loss: 0.8575 - val_accuracy: 0.6825\n",
      "Epoch 187/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1194 - accuracy: 0.9610 - val_loss: 0.7607 - val_accuracy: 0.7350\n",
      "Epoch 188/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9864 - val_loss: 0.8835 - val_accuracy: 0.6800\n",
      "Epoch 189/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0961 - accuracy: 0.9748 - val_loss: 0.7913 - val_accuracy: 0.7050\n",
      "Epoch 190/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9882 - val_loss: 0.7593 - val_accuracy: 0.7150\n",
      "Epoch 191/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0743 - accuracy: 0.9876 - val_loss: 0.7713 - val_accuracy: 0.7250\n",
      "Epoch 192/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9886 - val_loss: 0.8111 - val_accuracy: 0.7050\n",
      "Epoch 193/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 0.9863 - val_loss: 0.7913 - val_accuracy: 0.7250\n",
      "Epoch 194/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9924 - val_loss: 0.7865 - val_accuracy: 0.7250\n",
      "Epoch 195/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0738 - accuracy: 0.9873 - val_loss: 0.7732 - val_accuracy: 0.7250\n",
      "Epoch 196/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9877 - val_loss: 0.8160 - val_accuracy: 0.7025\n",
      "Epoch 197/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9938 - val_loss: 0.7795 - val_accuracy: 0.7400\n",
      "Epoch 198/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.9928 - val_loss: 0.7927 - val_accuracy: 0.7325\n",
      "Epoch 199/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0901 - accuracy: 0.9791 - val_loss: 0.7795 - val_accuracy: 0.7150\n",
      "Epoch 200/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.9946 - val_loss: 0.6700 - val_accuracy: 0.7000\n",
      "Epoch 201/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1651 - accuracy: 0.9592 - val_loss: 0.8137 - val_accuracy: 0.7175\n",
      "Epoch 202/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1114 - accuracy: 0.9694 - val_loss: 0.7553 - val_accuracy: 0.7375\n",
      "Epoch 203/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.9911 - val_loss: 1.3096 - val_accuracy: 0.6075\n",
      "Epoch 204/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1071 - accuracy: 0.9687 - val_loss: 0.8408 - val_accuracy: 0.6875\n",
      "Epoch 205/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.9897 - val_loss: 0.7739 - val_accuracy: 0.7300\n",
      "Epoch 206/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9952 - val_loss: 0.7563 - val_accuracy: 0.7350\n",
      "Epoch 207/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9860 - val_loss: 0.7771 - val_accuracy: 0.7300\n",
      "Epoch 208/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2328 - accuracy: 0.9338 - val_loss: 0.7541 - val_accuracy: 0.7100\n",
      "Epoch 209/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1178 - accuracy: 0.9701 - val_loss: 0.7942 - val_accuracy: 0.7375\n",
      "Epoch 210/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.9888 - val_loss: 0.7852 - val_accuracy: 0.7475\n",
      "Epoch 211/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1084 - accuracy: 0.9695 - val_loss: 0.8558 - val_accuracy: 0.7000\n",
      "Epoch 212/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0937 - accuracy: 0.9804 - val_loss: 0.7573 - val_accuracy: 0.7375\n",
      "Epoch 213/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.9863 - val_loss: 0.8568 - val_accuracy: 0.7275\n",
      "Epoch 214/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9911 - val_loss: 0.8267 - val_accuracy: 0.7325\n",
      "Epoch 215/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0515 - accuracy: 0.9952 - val_loss: 0.8144 - val_accuracy: 0.7300\n",
      "Epoch 216/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.9949 - val_loss: 0.8627 - val_accuracy: 0.7150\n",
      "Epoch 217/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9965 - val_loss: 0.8536 - val_accuracy: 0.7025\n",
      "Epoch 218/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9956 - val_loss: 0.8693 - val_accuracy: 0.7050\n",
      "Epoch 219/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9951 - val_loss: 0.8288 - val_accuracy: 0.7425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9980 - val_loss: 0.8111 - val_accuracy: 0.7300\n",
      "Epoch 221/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9965 - val_loss: 0.8341 - val_accuracy: 0.7200\n",
      "Epoch 222/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9957 - val_loss: 0.8890 - val_accuracy: 0.7050\n",
      "Epoch 223/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9873 - val_loss: 0.8244 - val_accuracy: 0.7300\n",
      "Epoch 224/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9874 - val_loss: 0.7200 - val_accuracy: 0.7350\n",
      "Epoch 225/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.9921 - val_loss: 0.8190 - val_accuracy: 0.7275\n",
      "Epoch 226/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9926 - val_loss: 0.8352 - val_accuracy: 0.7250\n",
      "Epoch 227/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9970 - val_loss: 0.9568 - val_accuracy: 0.7125\n",
      "Epoch 228/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0855 - accuracy: 0.9746 - val_loss: 0.8515 - val_accuracy: 0.7075\n",
      "Epoch 229/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9986 - val_loss: 0.8345 - val_accuracy: 0.7350\n",
      "Epoch 230/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 0.9965 - val_loss: 0.8505 - val_accuracy: 0.7300\n",
      "Epoch 231/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9993 - val_loss: 0.8764 - val_accuracy: 0.7050\n",
      "Epoch 232/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9975 - val_loss: 0.8841 - val_accuracy: 0.7250\n",
      "Epoch 233/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9940 - val_loss: 0.8520 - val_accuracy: 0.7225\n",
      "Epoch 234/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9993 - val_loss: 0.8483 - val_accuracy: 0.7250\n",
      "Epoch 235/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9999 - val_loss: 0.8617 - val_accuracy: 0.7400\n",
      "Epoch 236/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 0.9817 - val_loss: 0.8324 - val_accuracy: 0.7150\n",
      "Epoch 237/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9944 - val_loss: 0.8430 - val_accuracy: 0.7400\n",
      "Epoch 238/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9986 - val_loss: 0.8506 - val_accuracy: 0.7300\n",
      "Epoch 239/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.9991 - val_loss: 0.8654 - val_accuracy: 0.7125\n",
      "Epoch 240/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 0.9979 - val_loss: 0.9490 - val_accuracy: 0.7175\n",
      "Epoch 241/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9970 - val_loss: 0.8659 - val_accuracy: 0.7325\n",
      "Epoch 242/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9989 - val_loss: 0.8715 - val_accuracy: 0.7100\n",
      "Epoch 243/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.9405 - val_accuracy: 0.7000\n",
      "Epoch 244/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0333 - accuracy: 0.9998 - val_loss: 0.9063 - val_accuracy: 0.6975\n",
      "Epoch 245/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0330 - accuracy: 0.9999 - val_loss: 0.8651 - val_accuracy: 0.7325\n",
      "Epoch 246/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.9984 - val_loss: 0.8733 - val_accuracy: 0.7250\n",
      "Epoch 247/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9990 - val_loss: 0.8754 - val_accuracy: 0.7375\n",
      "Epoch 248/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.9986 - val_loss: 0.8661 - val_accuracy: 0.7200\n",
      "Epoch 249/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9993 - val_loss: 0.8883 - val_accuracy: 0.7225\n",
      "Epoch 250/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0295 - accuracy: 0.9997 - val_loss: 0.8802 - val_accuracy: 0.7150\n",
      "Epoch 251/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9916 - val_loss: 0.8706 - val_accuracy: 0.7175\n",
      "Epoch 252/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9989 - val_loss: 0.8802 - val_accuracy: 0.7250\n",
      "Epoch 253/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 0.9994 - val_loss: 0.8747 - val_accuracy: 0.7175\n",
      "Epoch 254/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.9994 - val_loss: 0.8991 - val_accuracy: 0.7075\n",
      "Epoch 255/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9995 - val_loss: 0.8762 - val_accuracy: 0.7300\n",
      "Epoch 256/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0305 - accuracy: 0.9993 - val_loss: 0.8830 - val_accuracy: 0.7300\n",
      "Epoch 257/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.9095 - val_accuracy: 0.7075\n",
      "Epoch 258/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.9993 - val_loss: 0.8903 - val_accuracy: 0.7200\n",
      "Epoch 259/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.8966 - val_accuracy: 0.7275\n",
      "Epoch 260/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0329 - accuracy: 0.9982 - val_loss: 0.8864 - val_accuracy: 0.7150\n",
      "Epoch 261/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9997 - val_loss: 0.9020 - val_accuracy: 0.7250\n",
      "Epoch 262/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9998 - val_loss: 0.8889 - val_accuracy: 0.7275\n",
      "Epoch 263/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.8893 - val_accuracy: 0.7275\n",
      "Epoch 264/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.8910 - val_accuracy: 0.7325\n",
      "Epoch 265/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.9239 - val_accuracy: 0.7150\n",
      "Epoch 266/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.8989 - val_accuracy: 0.7225\n",
      "Epoch 267/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9994 - val_loss: 0.9042 - val_accuracy: 0.7225\n",
      "Epoch 268/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 0.9993 - val_loss: 0.9009 - val_accuracy: 0.7225\n",
      "Epoch 269/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.8986 - val_accuracy: 0.7275\n",
      "Epoch 270/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.9990 - val_loss: 0.9094 - val_accuracy: 0.7150\n",
      "Epoch 271/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9998 - val_loss: 0.9028 - val_accuracy: 0.7225\n",
      "Epoch 272/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.9199 - val_accuracy: 0.7125\n",
      "Epoch 273/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.9150 - val_accuracy: 0.7275\n",
      "Epoch 274/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.9493 - val_accuracy: 0.7325\n",
      "Epoch 275/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.9148 - val_accuracy: 0.7175\n",
      "Epoch 276/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.9994 - val_loss: 0.9688 - val_accuracy: 0.7025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9989 - val_loss: 0.9093 - val_accuracy: 0.7300\n",
      "Epoch 278/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.9253 - val_accuracy: 0.7200\n",
      "Epoch 279/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9999 - val_loss: 0.9120 - val_accuracy: 0.7150\n",
      "Epoch 280/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.9162 - val_accuracy: 0.7175\n",
      "Epoch 281/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.9194 - val_accuracy: 0.7225\n",
      "Epoch 282/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.9418 - val_accuracy: 0.7325\n",
      "Epoch 283/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.9232 - val_accuracy: 0.7200\n",
      "Epoch 284/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.0680 - val_accuracy: 0.6825\n",
      "Epoch 285/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.9173 - val_accuracy: 0.7250\n",
      "Epoch 286/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.9244 - val_accuracy: 0.7225\n",
      "Epoch 287/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.9206 - val_accuracy: 0.7275\n",
      "Epoch 288/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.9222 - val_accuracy: 0.7225\n",
      "Epoch 289/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.9397 - val_accuracy: 0.7250\n",
      "Epoch 290/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.9237 - val_accuracy: 0.7275\n",
      "Epoch 291/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.9357 - val_accuracy: 0.7075\n",
      "Epoch 292/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.9743 - val_accuracy: 0.7075\n",
      "Epoch 293/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.9431 - val_accuracy: 0.7200\n",
      "Epoch 294/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.9483 - val_accuracy: 0.7200\n",
      "Epoch 295/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.9340 - val_accuracy: 0.7225\n",
      "Epoch 296/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.9495 - val_accuracy: 0.7175\n",
      "Epoch 297/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.9511 - val_accuracy: 0.7275\n",
      "Epoch 298/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.9376 - val_accuracy: 0.7200\n",
      "Epoch 299/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.9522 - val_accuracy: 0.7175\n",
      "Epoch 300/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.9460 - val_accuracy: 0.7225\n",
      "Epoch 301/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.9351 - val_accuracy: 0.7250\n",
      "Epoch 302/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.9380 - val_accuracy: 0.7225\n",
      "Epoch 303/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.9456 - val_accuracy: 0.7150\n",
      "Epoch 304/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.7150\n",
      "Epoch 305/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.9498 - val_accuracy: 0.7225\n",
      "Epoch 306/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.9567 - val_accuracy: 0.7200\n",
      "Epoch 307/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.9473 - val_accuracy: 0.7300\n",
      "Epoch 308/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.9588 - val_accuracy: 0.7200\n",
      "Epoch 309/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.9487 - val_accuracy: 0.7275\n",
      "Epoch 310/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.9566 - val_accuracy: 0.7225\n",
      "Epoch 311/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.9702 - val_accuracy: 0.7175\n",
      "Epoch 312/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.9578 - val_accuracy: 0.7250\n",
      "Epoch 313/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.9515 - val_accuracy: 0.7300\n",
      "Epoch 314/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.9590 - val_accuracy: 0.7200\n",
      "Epoch 315/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.9557 - val_accuracy: 0.7125\n",
      "Epoch 316/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.9591 - val_accuracy: 0.7125\n",
      "Epoch 317/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.9611 - val_accuracy: 0.7175\n",
      "Epoch 318/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.9660 - val_accuracy: 0.7300\n",
      "Epoch 319/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.9569 - val_accuracy: 0.7250\n",
      "Epoch 320/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.9594 - val_accuracy: 0.7225\n",
      "Epoch 321/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.0002 - val_accuracy: 0.7275\n",
      "Epoch 322/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.9778 - val_accuracy: 0.7175\n",
      "Epoch 323/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.9560 - val_accuracy: 0.7250\n",
      "Epoch 324/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.9693 - val_accuracy: 0.7175\n",
      "Epoch 325/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.9637 - val_accuracy: 0.7175\n",
      "Epoch 326/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.9720 - val_accuracy: 0.7225\n",
      "Epoch 327/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.9722 - val_accuracy: 0.7200\n",
      "Epoch 328/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.9813 - val_accuracy: 0.7275\n",
      "Epoch 329/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.9713 - val_accuracy: 0.7200\n",
      "Epoch 330/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.9818 - val_accuracy: 0.7175\n",
      "Epoch 331/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.9705 - val_accuracy: 0.7150\n",
      "Epoch 332/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.0192 - val_accuracy: 0.7125\n",
      "Epoch 333/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.9733 - val_accuracy: 0.7300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.9767 - val_accuracy: 0.7150\n",
      "Epoch 335/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.9757 - val_accuracy: 0.7125\n",
      "Epoch 336/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.9771 - val_accuracy: 0.7150\n",
      "Epoch 337/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.0023 - val_accuracy: 0.7250\n",
      "Epoch 338/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.9797 - val_accuracy: 0.7225\n",
      "Epoch 339/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.9782 - val_accuracy: 0.7200\n",
      "Epoch 340/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.9778 - val_accuracy: 0.7150\n",
      "Epoch 341/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.9818 - val_accuracy: 0.7300\n",
      "Epoch 342/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.9807 - val_accuracy: 0.7200\n",
      "Epoch 343/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.9970 - val_accuracy: 0.7200\n",
      "Epoch 344/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.9881 - val_accuracy: 0.7125\n",
      "Epoch 345/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.9813 - val_accuracy: 0.7150\n",
      "Epoch 346/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.9908 - val_accuracy: 0.7225\n",
      "Epoch 347/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.9894 - val_accuracy: 0.7175\n",
      "Epoch 348/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.9901 - val_accuracy: 0.7125\n",
      "Epoch 349/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.0093 - val_accuracy: 0.7275\n",
      "Epoch 350/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.0163 - val_accuracy: 0.7275\n",
      "Epoch 351/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.9867 - val_accuracy: 0.7200\n",
      "Epoch 352/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.9898 - val_accuracy: 0.7125\n",
      "Epoch 353/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.9921 - val_accuracy: 0.7175\n",
      "Epoch 354/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.9946 - val_accuracy: 0.7225\n",
      "Epoch 355/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.0025 - val_accuracy: 0.7225\n",
      "Epoch 356/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.9975 - val_accuracy: 0.7150\n",
      "Epoch 357/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.9935 - val_accuracy: 0.7150\n",
      "Epoch 358/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.0047 - val_accuracy: 0.7225\n",
      "Epoch 359/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.9951 - val_accuracy: 0.7175\n",
      "Epoch 360/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.9974 - val_accuracy: 0.7175\n",
      "Epoch 361/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.9982 - val_accuracy: 0.7150\n",
      "Epoch 362/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.0045 - val_accuracy: 0.7200\n",
      "Epoch 363/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.0020 - val_accuracy: 0.7125\n",
      "Epoch 364/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.0055 - val_accuracy: 0.7200\n",
      "Epoch 365/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.0015 - val_accuracy: 0.7175\n",
      "Epoch 366/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.0044 - val_accuracy: 0.7150\n",
      "Epoch 367/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.0326 - val_accuracy: 0.7275\n",
      "Epoch 368/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.0086 - val_accuracy: 0.7225\n",
      "Epoch 369/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.0105 - val_accuracy: 0.7200\n",
      "Epoch 370/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.0062 - val_accuracy: 0.7225\n",
      "Epoch 371/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.0076 - val_accuracy: 0.7175\n",
      "Epoch 372/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.0131 - val_accuracy: 0.7200\n",
      "Epoch 373/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.0124 - val_accuracy: 0.7150\n",
      "Epoch 374/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.0072 - val_accuracy: 0.7075\n",
      "Epoch 375/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.0175 - val_accuracy: 0.7275\n",
      "Epoch 376/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.0167 - val_accuracy: 0.7100\n",
      "Epoch 377/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.0316 - val_accuracy: 0.7350\n",
      "Epoch 378/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.0166 - val_accuracy: 0.7225\n",
      "Epoch 379/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.0167 - val_accuracy: 0.7150\n",
      "Epoch 380/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.0134 - val_accuracy: 0.7100\n",
      "Epoch 381/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.0132 - val_accuracy: 0.7125\n",
      "Epoch 382/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.0207 - val_accuracy: 0.7175\n",
      "Epoch 383/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.0213 - val_accuracy: 0.7175\n",
      "Epoch 384/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.0188 - val_accuracy: 0.7150\n",
      "Epoch 385/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.0248 - val_accuracy: 0.7150\n",
      "Epoch 386/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.0222 - val_accuracy: 0.7175\n",
      "Epoch 387/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.0205 - val_accuracy: 0.7125\n",
      "Epoch 388/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.0206 - val_accuracy: 0.7200\n",
      "Epoch 389/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.0190 - val_accuracy: 0.7175\n",
      "Epoch 390/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.0210 - val_accuracy: 0.7250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.0162 - val_accuracy: 0.7125\n",
      "Epoch 392/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.0308 - val_accuracy: 0.7225\n",
      "Epoch 393/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.0247 - val_accuracy: 0.7175\n",
      "Epoch 394/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.0229 - val_accuracy: 0.7200\n",
      "Epoch 395/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.0315 - val_accuracy: 0.7200\n",
      "Epoch 396/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.0222 - val_accuracy: 0.7125\n",
      "Epoch 397/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.0242 - val_accuracy: 0.7150\n",
      "Epoch 398/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.0322 - val_accuracy: 0.7150\n",
      "Epoch 399/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.0540 - val_accuracy: 0.7250\n",
      "Epoch 400/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.0288 - val_accuracy: 0.7200\n",
      "Epoch 401/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.0293 - val_accuracy: 0.7200\n",
      "Epoch 402/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.0303 - val_accuracy: 0.7150\n",
      "Epoch 403/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.0573 - val_accuracy: 0.7250\n",
      "Epoch 404/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.0328 - val_accuracy: 0.7225\n",
      "Epoch 405/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.0307 - val_accuracy: 0.7175\n",
      "Epoch 406/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.0322 - val_accuracy: 0.7200\n",
      "Epoch 407/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.0420 - val_accuracy: 0.7200\n",
      "Epoch 408/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.0400 - val_accuracy: 0.7075\n",
      "Epoch 409/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.0367 - val_accuracy: 0.7150\n",
      "Epoch 410/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.0391 - val_accuracy: 0.7150\n",
      "Epoch 411/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.0338 - val_accuracy: 0.7175\n",
      "Epoch 412/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.0367 - val_accuracy: 0.7250\n",
      "Epoch 413/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.0367 - val_accuracy: 0.7150\n",
      "Epoch 414/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.0376 - val_accuracy: 0.7200\n",
      "Epoch 415/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.0390 - val_accuracy: 0.7150\n",
      "Epoch 416/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.0403 - val_accuracy: 0.7150\n",
      "Epoch 417/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.0392 - val_accuracy: 0.7200\n",
      "Epoch 418/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.0455 - val_accuracy: 0.7175\n",
      "Epoch 419/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.0448 - val_accuracy: 0.7175\n",
      "Epoch 420/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.0442 - val_accuracy: 0.7150\n",
      "Epoch 421/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.0432 - val_accuracy: 0.7150\n",
      "Epoch 422/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.0511 - val_accuracy: 0.7200\n",
      "Epoch 423/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.0426 - val_accuracy: 0.7125\n",
      "Epoch 424/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.0490 - val_accuracy: 0.7200\n",
      "Epoch 425/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.0455 - val_accuracy: 0.7150\n",
      "Epoch 426/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.0482 - val_accuracy: 0.7175\n",
      "Epoch 427/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.0549 - val_accuracy: 0.7275\n",
      "Epoch 428/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.0466 - val_accuracy: 0.7100\n",
      "Epoch 429/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.0509 - val_accuracy: 0.7175\n",
      "Epoch 430/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.0582 - val_accuracy: 0.7175\n",
      "Epoch 431/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.0506 - val_accuracy: 0.7125\n",
      "Epoch 432/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.0526 - val_accuracy: 0.7150\n",
      "Epoch 433/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.0640 - val_accuracy: 0.7200\n",
      "Epoch 434/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.0510 - val_accuracy: 0.7200\n",
      "Epoch 435/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.0597 - val_accuracy: 0.7225\n",
      "Epoch 436/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.0516 - val_accuracy: 0.7100\n",
      "Epoch 437/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.0557 - val_accuracy: 0.7125\n",
      "Epoch 438/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.0538 - val_accuracy: 0.7175\n",
      "Epoch 439/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.0581 - val_accuracy: 0.7125\n",
      "Epoch 440/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.0577 - val_accuracy: 0.7125\n",
      "Epoch 441/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.0741 - val_accuracy: 0.7200\n",
      "Epoch 442/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.0660 - val_accuracy: 0.7150\n",
      "Epoch 443/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.0573 - val_accuracy: 0.7150\n",
      "Epoch 444/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.0618 - val_accuracy: 0.7150\n",
      "Epoch 445/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.0616 - val_accuracy: 0.7175\n",
      "Epoch 446/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.0648 - val_accuracy: 0.7100\n",
      "Epoch 447/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.0602 - val_accuracy: 0.7150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.0586 - val_accuracy: 0.7175\n",
      "Epoch 449/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.0772 - val_accuracy: 0.7225\n",
      "Epoch 450/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.0637 - val_accuracy: 0.7225\n",
      "Epoch 451/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.0633 - val_accuracy: 0.7150\n",
      "Epoch 452/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.0647 - val_accuracy: 0.7150\n",
      "Epoch 453/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.0627 - val_accuracy: 0.7150\n",
      "Epoch 454/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.0708 - val_accuracy: 0.7225\n",
      "Epoch 455/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.0647 - val_accuracy: 0.7125\n",
      "Epoch 456/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.0694 - val_accuracy: 0.7125\n",
      "Epoch 457/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.0697 - val_accuracy: 0.7100\n",
      "Epoch 458/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.0690 - val_accuracy: 0.7125\n",
      "Epoch 459/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.0784 - val_accuracy: 0.7200\n",
      "Epoch 460/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.0684 - val_accuracy: 0.7150\n",
      "Epoch 461/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.0682 - val_accuracy: 0.7175\n",
      "Epoch 462/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.0733 - val_accuracy: 0.7250\n",
      "Epoch 463/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.0682 - val_accuracy: 0.7125\n",
      "Epoch 464/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.0708 - val_accuracy: 0.7200\n",
      "Epoch 465/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.0681 - val_accuracy: 0.7125\n",
      "Epoch 466/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.0742 - val_accuracy: 0.7175\n",
      "Epoch 467/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.0733 - val_accuracy: 0.7125\n",
      "Epoch 468/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.0831 - val_accuracy: 0.7200\n",
      "Epoch 469/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.0769 - val_accuracy: 0.7225\n",
      "Epoch 470/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.0708 - val_accuracy: 0.7150\n",
      "Epoch 471/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.0711 - val_accuracy: 0.7100\n",
      "Epoch 472/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.0713 - val_accuracy: 0.7100\n",
      "Epoch 473/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.0788 - val_accuracy: 0.7175\n",
      "Epoch 474/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.0826 - val_accuracy: 0.7225\n",
      "Epoch 475/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.0742 - val_accuracy: 0.7100\n",
      "Epoch 476/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.0778 - val_accuracy: 0.7175\n",
      "Epoch 477/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.0795 - val_accuracy: 0.7150\n",
      "Epoch 478/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.0800 - val_accuracy: 0.7125\n",
      "Epoch 479/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.0811 - val_accuracy: 0.7100\n",
      "Epoch 480/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.0816 - val_accuracy: 0.7150\n",
      "Epoch 481/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.0814 - val_accuracy: 0.7150\n",
      "Epoch 482/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.0853 - val_accuracy: 0.7125\n",
      "Epoch 483/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.0863 - val_accuracy: 0.7125\n",
      "Epoch 484/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.0827 - val_accuracy: 0.7200\n",
      "Epoch 485/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.0884 - val_accuracy: 0.7150\n",
      "Epoch 486/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.0825 - val_accuracy: 0.7150\n",
      "Epoch 487/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.0861 - val_accuracy: 0.7275\n",
      "Epoch 488/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.0928 - val_accuracy: 0.7175\n",
      "Epoch 489/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.0817 - val_accuracy: 0.7125\n",
      "Epoch 490/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.0933 - val_accuracy: 0.7150\n",
      "Epoch 491/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.0850 - val_accuracy: 0.7100\n",
      "Epoch 492/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.0905 - val_accuracy: 0.7250\n",
      "Epoch 493/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0918 - val_accuracy: 0.7225\n",
      "Epoch 494/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.0961 - val_accuracy: 0.7150\n",
      "Epoch 495/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.0899 - val_accuracy: 0.7125\n",
      "Epoch 496/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.0914 - val_accuracy: 0.7175\n",
      "Epoch 497/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.0927 - val_accuracy: 0.7200\n",
      "Epoch 498/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.0906 - val_accuracy: 0.7175\n",
      "Epoch 499/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.0898 - val_accuracy: 0.7150\n",
      "Epoch 500/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.0962 - val_accuracy: 0.7200\n",
      "Epoch 501/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.0961 - val_accuracy: 0.7075\n",
      "Epoch 502/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.0959 - val_accuracy: 0.7150\n",
      "Epoch 503/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.0930 - val_accuracy: 0.7150\n",
      "Epoch 504/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.0968 - val_accuracy: 0.7200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.1077 - val_accuracy: 0.7200\n",
      "Epoch 506/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.1022 - val_accuracy: 0.7225\n",
      "Epoch 507/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.0968 - val_accuracy: 0.7200\n",
      "Epoch 508/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0995 - val_accuracy: 0.7225\n",
      "Epoch 509/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.1062 - val_accuracy: 0.7175\n",
      "Epoch 510/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.1038 - val_accuracy: 0.7175\n",
      "Epoch 511/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.1003 - val_accuracy: 0.7125\n",
      "Epoch 512/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.0978 - val_accuracy: 0.7200\n",
      "Epoch 513/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.0987 - val_accuracy: 0.7125\n",
      "Epoch 514/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.1016 - val_accuracy: 0.7175\n",
      "Epoch 515/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.1059 - val_accuracy: 0.7175\n",
      "Epoch 516/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0997 - val_accuracy: 0.7150\n",
      "Epoch 517/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.1026 - val_accuracy: 0.7150\n",
      "Epoch 518/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.1062 - val_accuracy: 0.7150\n",
      "Epoch 519/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.0957 - val_accuracy: 0.7175\n",
      "Epoch 520/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.0967 - val_accuracy: 0.7125\n",
      "Epoch 521/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.1169 - val_accuracy: 0.7250\n",
      "Epoch 522/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1097 - val_accuracy: 0.7125\n",
      "Epoch 523/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.1114 - val_accuracy: 0.7175\n",
      "Epoch 524/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.1053 - val_accuracy: 0.7200\n",
      "Epoch 525/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1051 - val_accuracy: 0.7225\n",
      "Epoch 526/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1028 - val_accuracy: 0.7200\n",
      "Epoch 527/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.1069 - val_accuracy: 0.7100\n",
      "Epoch 528/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1070 - val_accuracy: 0.7150\n",
      "Epoch 529/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.1076 - val_accuracy: 0.7150\n",
      "Epoch 530/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1090 - val_accuracy: 0.7275\n",
      "Epoch 531/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1040 - val_accuracy: 0.7125\n",
      "Epoch 532/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1105 - val_accuracy: 0.7125\n",
      "Epoch 533/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1086 - val_accuracy: 0.7150\n",
      "Epoch 534/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1093 - val_accuracy: 0.7175\n",
      "Epoch 535/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1112 - val_accuracy: 0.7150\n",
      "Epoch 536/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1193 - val_accuracy: 0.7150\n",
      "Epoch 537/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1089 - val_accuracy: 0.7100\n",
      "Epoch 538/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1142 - val_accuracy: 0.7175\n",
      "Epoch 539/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1129 - val_accuracy: 0.7150\n",
      "Epoch 540/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1088 - val_accuracy: 0.7175\n",
      "Epoch 541/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1106 - val_accuracy: 0.7200\n",
      "Epoch 542/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1095 - val_accuracy: 0.7100\n",
      "Epoch 543/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1123 - val_accuracy: 0.7125\n",
      "Epoch 544/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1154 - val_accuracy: 0.7125\n",
      "Epoch 545/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1145 - val_accuracy: 0.7125\n",
      "Epoch 546/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1134 - val_accuracy: 0.7125\n",
      "Epoch 547/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1204 - val_accuracy: 0.7125\n",
      "Epoch 548/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1156 - val_accuracy: 0.7125\n",
      "Epoch 549/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1168 - val_accuracy: 0.7200\n",
      "Epoch 550/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1174 - val_accuracy: 0.7100\n",
      "Epoch 551/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1155 - val_accuracy: 0.7175\n",
      "Epoch 552/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1199 - val_accuracy: 0.7175\n",
      "Epoch 553/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1193 - val_accuracy: 0.7150\n",
      "Epoch 554/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1169 - val_accuracy: 0.7150\n",
      "Epoch 555/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1205 - val_accuracy: 0.7100\n",
      "Epoch 556/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1190 - val_accuracy: 0.7175\n",
      "Epoch 557/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1203 - val_accuracy: 0.7175\n",
      "Epoch 558/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1225 - val_accuracy: 0.7150\n",
      "Epoch 559/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1185 - val_accuracy: 0.7100\n",
      "Epoch 560/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1237 - val_accuracy: 0.7150\n",
      "Epoch 561/1000\n",
      "24/63 [==========>...................] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#to load matlab mat files\n",
    "from scipy.io import loadmat\n",
    "# for neural network\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# for saving metrics\n",
    "import os \n",
    "import json\n",
    "\n",
    "if not os.path.exists('./metrics'):\n",
    "        os.makedirs('./metrics')\n",
    "\n",
    "for labelNames in labelsGroup:\n",
    "    # LOAD FILES\n",
    "    print(\"\\n\\nLABELS\", ', '.join(labelNames))\n",
    "\n",
    "    # Load Training data\n",
    "    mat=loadmat(f\"../datasets/train/{'_'.join(labelNames)}.mat\")\n",
    "    # mat is a dict with key \"X\" for x-values, and key \"y\" for y values\n",
    "    X, y = mat[\"X\"], mat[\"y\"]\n",
    "\n",
    "    # Load Dev Data\n",
    "    matDev=loadmat(f\"../datasets/dev/{'_'.join(labelNames)}.mat\")\n",
    "    X_valid, y_valid = matDev[\"X\"], matDev[\"y\"]\n",
    "\n",
    "    # Load Test Data\n",
    "    matTest=loadmat(f\"../datasets/test/{'_'.join(labelNames)}.mat\")\n",
    "    X_test, y_test = matTest[\"X\"], matTest[\"y\"]\n",
    "    \n",
    "    # NUMBERS\n",
    "    m = X.shape[0] # number of training examples\n",
    "    labels = np.max(y)+1 # number of labels\n",
    "    features = X.shape[1] # number of features per example\n",
    "\n",
    "    print(f\"Loaded {m} traing examples with {labels} labels, each with {features} features (pixels).\")\n",
    "    print(f\"Loaded {X_valid.shape[0]} dev examples.\")\n",
    "    print(f\"Loaded {X_test.shape[0]} test examples.\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Create folder for metrics\n",
    "    folder = f\"./metrics/{'_'.join(labelNames)}\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    for iterations in iterationsGroup:\n",
    "        for hiddenLayers in hiddenLayersGroup:\n",
    "            \n",
    "            hiddenLayersText = '_'.join(hiddenLayers) if len(hiddenLayers)>1 else hiddenLayers[0]\n",
    "            \n",
    "            # Create folder for metrics\n",
    "            folder = f\"{folder}/{iterations}i_{len(hiddenLayers)}hl__{hiddenLayersText}\"\n",
    "            if not os.path.exists(folder):\n",
    "                os.makedirs(folder)\n",
    "            \n",
    "            print(f\"\\nBuilding network for {iterations} iterations and {len(hiddenLayers)} hidden layers: {hiddenLayersText}...\\n\")\n",
    "            \n",
    "            # BUILD NETWORK\n",
    "            # Create model\n",
    "            modelSeq = []\n",
    "            # Flattens each image (48x48) to 1x2304\n",
    "            modelSeq.append(keras.layers.Flatten(input_shape = [48, 48]))\n",
    "            # Hidden layers with relu activation function\n",
    "            for h in hiddenLayers:\n",
    "                modelSeq.append(keras.layers.Dense(h, activation = \"relu\" ))\n",
    "            # Output layer with softmax activation function\n",
    "            modelSeq.append(keras.layers.Dense(labels, activation = \"softmax\" ))\n",
    "\n",
    "            model = keras.models.Sequential(modelSeq)\n",
    "\n",
    "            # Compile model\n",
    "            model.compile(\n",
    "                # Using sparse categorical crossentropy loss function\n",
    "                loss = \"sparse_categorical_crossentropy\",\n",
    "                # Using stochastic gradient descent as gradient descent\n",
    "                optimizer = \"sgd\",\n",
    "                # In addition to cost, we want accuracy to help understanding how the model is working \n",
    "                metrics = [\"accuracy\"]\n",
    "            )\n",
    "\n",
    "            # Train the network\n",
    "            history = model.fit(\n",
    "                X,\n",
    "                y,\n",
    "                epochs = iterations,\n",
    "                # batch_size = iteratios/10,\n",
    "                validation_data = (X_valid, y_valid)\n",
    "            )\n",
    "\n",
    "            # METRICS (SAVE TO FILE)\n",
    "            \n",
    "            # Model training history\n",
    "            with open(f\"{folder}/history.json\", \"w\") as f:\n",
    "                json.dump(history.history, f)\n",
    "            \n",
    "            # Test model evaluation\n",
    "            with open(f\"{folder}/evaluation.json\", \"w\") as f:\n",
    "                json.dump(model.evaluate(X_test, y_test, return_dict=True), f)\n",
    "            \n",
    "            # Prediction for test data\n",
    "            with open(f\"{folder}/predict.json\", \"w\") as f:\n",
    "                json.dump(model.predict(X_test).tolist(), f)\n",
    "                \n",
    "            print(f\"\\nModel trained and metrics saved to {folder}!\")\n",
    "            \n",
    "            # GENERATE GRAPHS AND SAVE TO FILE\n",
    "            \n",
    "            # Model training history\n",
    "            pd.DataFrame(history.history).plot(figsize = (16, 10))\n",
    "            plt.grid(True)\n",
    "            plt.gca().set_ylim(0, 1)\n",
    "            plt.title(\"Neural network training metrics\")\n",
    "            plt.savefig(f\"{folder}/history.png\")\n",
    "            \n",
    "            # Prediction for test data\n",
    "            predict = model.predict(X_test)\n",
    "            y_pred = np.array([np.argmax(p) for p in predict])\n",
    "            confusionTFPN, confusionLabels = confusionMatrix(labelNames, y_pred, y_test)\n",
    "            fig, axs = plt.subplots(2,1)\n",
    "            outputConfusionTables(labelNames, y_test.size, confusionTFPN, confusionLabels, axs, 0, \"WITHOUT regularization\")\n",
    "            fig.set_size_inches(18,6*len(labelNames))\n",
    "            fig.subplots_adjust(left=0.2, top=20)\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(f\"{folder}/predict.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
